{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6.2 transformer_multi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwxEmAcAkgfp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "044a61b5-aeda-46df-8763-7cf7144ba00f"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "datadir = '/content/gdrive/My Drive/colab/TimeSeries/dataset/7'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJtqOYt3khm1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "from matplotlib import pyplot\n",
        "import pandas as pd\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# S is the source sequence length\n",
        "# T is the target sequence length\n",
        "# N is the batch size\n",
        "# E is the feature number\n",
        "\n",
        "#src = torch.rand((10, 32, 512)) # (S,N,E) \n",
        "#tgt = torch.rand((20, 32, 512)) # (T,N,E)\n",
        "#out = transformer_model(src, tgt)\n",
        "#\n",
        "#print(out)\n",
        "\n",
        "input_window = 100\n",
        "output_window = 5 # multistep prediction      # 10\n",
        "batch_size = 10 # batch size                  # 3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq_Jl5WZVn6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()       \n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        #pe.requires_grad = False\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "       \n",
        "\n",
        "class TransAm(nn.Module):\n",
        "    def __init__(self,feature_size=250,num_layers=1,dropout=0.1):\n",
        "        super(TransAm, self).__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        \n",
        "        self.src_mask = None\n",
        "        self.pos_encoder = PositionalEncoding(feature_size)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
        "        self.decoder = nn.Linear(feature_size,1)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1    \n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self,src):\n",
        "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
        "            device = src.device\n",
        "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
        "            self.src_mask = mask\n",
        "\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src,self.src_mask)#, self.src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "\n",
        "\n",
        "# if window is 100 and prediction step is 1\n",
        "# in -> [0..99]\n",
        "# target -> [1..100]\n",
        "def create_inout_sequences(input_data, tw):\n",
        "    inout_seq = []\n",
        "    L = len(input_data)\n",
        "    for i in range(L-tw):\n",
        "        train_seq = np.append(input_data[i:i+tw][:-output_window] , output_window * [0])\n",
        "        train_label = input_data[i:i+tw]\n",
        "        #train_label = input_data[i+output_window:i+tw+output_window]\n",
        "        inout_seq.append((train_seq ,train_label))\n",
        "    return torch.FloatTensor(inout_seq)\n",
        "\n",
        "def get_data():\n",
        "\n",
        "    #time        = np.arange(0, 400, 0.1)\n",
        "    #amplitude   = np.sin(time) + np.sin(time*0.05) +np.sin(time*0.12) *np.random.normal(-0.2, 0.2, len(time))\n",
        "    \n",
        "    #from pandas import read_csv\n",
        "    series = pd.read_csv(datadir + '/daily-min-temperatures.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
        "    \n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    scaler = MinMaxScaler(feature_range=(-1, 1)) \n",
        "    amplitude = series.to_numpy()\n",
        "    amplitude = scaler.fit_transform(amplitude.reshape(-1, 1)).reshape(-1)\n",
        "    \n",
        "    \n",
        "    sampels = 2800\n",
        "    train_data = amplitude[:sampels]\n",
        "    test_data = amplitude[sampels:]\n",
        "\n",
        "    # convert our train data into a pytorch train tensor\n",
        "    #train_tensor = torch.FloatTensor(train_data).view(-1)\n",
        "    # todo: add comment.. \n",
        "    train_sequence = create_inout_sequences(train_data,input_window)\n",
        "    train_sequence = train_sequence[:-output_window] #todo: fix hack?\n",
        "\n",
        "    #test_data = torch.FloatTensor(test_data).view(-1) \n",
        "    test_data = create_inout_sequences(test_data,input_window)\n",
        "    test_data = train_sequence[:-output_window] #todo: fix hack?\n",
        "\n",
        "    return train_sequence.to(device),test_data.to(device)\n",
        "\n",
        "def get_batch(source, i,batch_size):\n",
        "    seq_len = min(batch_size, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]    \n",
        "    input = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window,1)) # 1 is feature size\n",
        "    target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window,1))\n",
        "    return input, target\n",
        "\n",
        "\n",
        "def train(train_data):\n",
        "    model.train() # Turn on the train mode\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "\n",
        "    for batch, i in enumerate(range(0, len(train_data) - 1, batch_size)):\n",
        "        data, targets = get_batch(train_data, i,batch_size)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)        \n",
        "        loss = criterion(output[-output_window:], targets[-output_window:])\n",
        "        #loss = criterion(output, targets)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        log_interval = int(len(train_data) / batch_size / 5)\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "                  'lr {:02.6f} | {:5.2f} ms | '\n",
        "                  'loss {:5.5f} | ppl {:8.2f}'.format(\n",
        "                    epoch, batch, len(train_data) // batch_size, scheduler.get_lr()[0],\n",
        "                    elapsed * 1000 / log_interval,\n",
        "                    cur_loss, math.exp(cur_loss)))\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def plot_and_loss(eval_model, data_source,epoch):\n",
        "    eval_model.eval() \n",
        "    total_loss = 0.\n",
        "    test_result = torch.Tensor(0)    \n",
        "    truth = torch.Tensor(0)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(data_source) - 1):\n",
        "            data, target = get_batch(data_source, i,1)\n",
        "            # look like the model returns static values for the output window\n",
        "            output = eval_model(data)                    \n",
        "            total_loss += criterion(output[-output_window:], target[-output_window:]).item()\n",
        "            #total_loss += criterion(output, target).item()\n",
        "            test_result = torch.cat((test_result, output[-1].view(-1).cpu()), 0) #todo: check this. -> looks good to me\n",
        "            truth = torch.cat((truth, target[-1].view(-1).cpu()), 0)\n",
        "            \n",
        "    #test_result = test_result.cpu().numpy()\n",
        "    len(test_result)\n",
        "\n",
        "    pyplot.plot(test_result,color=\"red\")\n",
        "    pyplot.plot(truth[:500],color=\"blue\")\n",
        "    pyplot.plot(test_result-truth,color=\"green\")\n",
        "    pyplot.grid(True, which='both')\n",
        "    pyplot.axhline(y=0, color='k')\n",
        "    pyplot.savefig(datadir + '/graph/transformer-epoch%d.png'%epoch)\n",
        "    pyplot.close()\n",
        "    \n",
        "    return total_loss / i\n",
        "\n",
        "\n",
        "def predict_future(eval_model, data_source,steps):\n",
        "    eval_model.eval() \n",
        "    total_loss = 0.\n",
        "    test_result = torch.Tensor(0)    \n",
        "    truth = torch.Tensor(0)\n",
        "    _ , data = get_batch(data_source, 0,1)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, steps,1):\n",
        "            input = torch.clone(data[-input_window:])\n",
        "            input[-output_window:] = 0     \n",
        "            output = eval_model(data[-input_window:])                        \n",
        "            data = torch.cat((data, output[-1:]))\n",
        "            \n",
        "    data = data.cpu().view(-1)\n",
        "    \n",
        "\n",
        "    pyplot.plot(data,color=\"red\")       \n",
        "    pyplot.plot(data[:input_window],color=\"blue\")\n",
        "    pyplot.grid(True, which='both')\n",
        "    pyplot.axhline(y=0, color='k')\n",
        "    pyplot.savefig(datadir + '/transformer-multi-future%d.png'%steps)\n",
        "    pyplot.close()\n",
        "        \n",
        "# entweder ist hier ein fehler im loss oder in der train methode, aber die ergebnisse sind unterschiedlich \n",
        "# auch zu denen der predict_future\n",
        "def evaluate(eval_model, data_source):\n",
        "    eval_model.eval() # Turn on the evaluation mode\n",
        "    total_loss = 0.\n",
        "    eval_batch_size = 1000\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(data_source) - 1, eval_batch_size):\n",
        "            data, targets = get_batch(data_source, i,eval_batch_size)\n",
        "            output = eval_model(data)            \n",
        "            total_loss += len(data[0])* criterion(output[-output_window:], targets[-output_window:]).cpu().item()\n",
        "            # total_loss += len(data[0])* criterion(output, targets).cpu().item()\n",
        "    return total_loss / i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLKi-Bd39wEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "310c6196-8012-46e9-ba61-f40aa3f2c058"
      },
      "source": [
        "train_data, val_data = get_data()\n",
        "model = TransAm().to(device)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "lr = 0.005 \n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
        "\n",
        "best_val_loss = float(\"inf\")\n",
        "epochs = 100 # The number of epochs\n",
        "best_model = None\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(train_data)\n",
        "    \n",
        "    \n",
        "    if(epoch % 10 is 0):\n",
        "        val_loss = plot_and_loss(model, val_data,epoch)\n",
        "        predict_future(model, val_data,200)\n",
        "    else:\n",
        "        val_loss = evaluate(model, val_data)\n",
        "        \n",
        "    print('-' * 89)\n",
        "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.5f} | valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
        "                                     val_loss, math.exp(val_loss)))\n",
        "    print('-' * 89)\n",
        "\n",
        "    #if val_loss < best_val_loss:\n",
        "    #    best_val_loss = val_loss\n",
        "    #    best_model = model\n",
        "\n",
        "    scheduler.step() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch   1 |    53/  269 batches | lr 0.005000 | 23.83 ms | loss 5.31915 | ppl   204.21\n",
            "| epoch   1 |   106/  269 batches | lr 0.005000 | 14.21 ms | loss 0.08926 | ppl     1.09\n",
            "| epoch   1 |   159/  269 batches | lr 0.005000 | 14.01 ms | loss 0.09312 | ppl     1.10\n",
            "| epoch   1 |   212/  269 batches | lr 0.005000 | 14.00 ms | loss 0.05412 | ppl     1.06\n",
            "| epoch   1 |   265/  269 batches | lr 0.005000 | 14.01 ms | loss 0.04681 | ppl     1.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time:  4.89s | valid loss 0.14884 | valid ppl     1.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |    53/  269 batches | lr 0.004802 | 14.30 ms | loss 0.06472 | ppl     1.07\n",
            "| epoch   2 |   106/  269 batches | lr 0.004802 | 14.26 ms | loss 0.07996 | ppl     1.08\n",
            "| epoch   2 |   159/  269 batches | lr 0.004802 | 14.19 ms | loss 0.08112 | ppl     1.08\n",
            "| epoch   2 |   212/  269 batches | lr 0.004802 | 13.86 ms | loss 0.04447 | ppl     1.05\n",
            "| epoch   2 |   265/  269 batches | lr 0.004802 | 13.86 ms | loss 0.05347 | ppl     1.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time:  4.38s | valid loss 0.24251 | valid ppl     1.27\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |    53/  269 batches | lr 0.004706 | 14.24 ms | loss 0.07974 | ppl     1.08\n",
            "| epoch   3 |   106/  269 batches | lr 0.004706 | 13.99 ms | loss 0.07159 | ppl     1.07\n",
            "| epoch   3 |   159/  269 batches | lr 0.004706 | 13.89 ms | loss 0.07528 | ppl     1.08\n",
            "| epoch   3 |   212/  269 batches | lr 0.004706 | 13.88 ms | loss 0.05409 | ppl     1.06\n",
            "| epoch   3 |   265/  269 batches | lr 0.004706 | 13.74 ms | loss 0.05097 | ppl     1.05\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time:  4.35s | valid loss 0.23099 | valid ppl     1.26\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   4 |    53/  269 batches | lr 0.004612 | 14.43 ms | loss 0.13052 | ppl     1.14\n",
            "| epoch   4 |   106/  269 batches | lr 0.004612 | 13.86 ms | loss 0.08128 | ppl     1.08\n",
            "| epoch   4 |   159/  269 batches | lr 0.004612 | 13.86 ms | loss 0.08136 | ppl     1.08\n",
            "| epoch   4 |   212/  269 batches | lr 0.004612 | 14.13 ms | loss 0.06067 | ppl     1.06\n",
            "| epoch   4 |   265/  269 batches | lr 0.004612 | 13.96 ms | loss 0.06030 | ppl     1.06\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   4 | time:  4.36s | valid loss 0.22513 | valid ppl     1.25\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   5 |    53/  269 batches | lr 0.004520 | 14.35 ms | loss 0.12277 | ppl     1.13\n",
            "| epoch   5 |   106/  269 batches | lr 0.004520 | 14.17 ms | loss 0.08607 | ppl     1.09\n",
            "| epoch   5 |   159/  269 batches | lr 0.004520 | 13.87 ms | loss 0.08225 | ppl     1.09\n",
            "| epoch   5 |   212/  269 batches | lr 0.004520 | 13.84 ms | loss 0.06503 | ppl     1.07\n",
            "| epoch   5 |   265/  269 batches | lr 0.004520 | 13.81 ms | loss 0.07445 | ppl     1.08\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   5 | time:  4.36s | valid loss 0.26343 | valid ppl     1.30\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   6 |    53/  269 batches | lr 0.004429 | 14.38 ms | loss 0.12570 | ppl     1.13\n",
            "| epoch   6 |   106/  269 batches | lr 0.004429 | 13.92 ms | loss 0.12324 | ppl     1.13\n",
            "| epoch   6 |   159/  269 batches | lr 0.004429 | 14.02 ms | loss 0.11762 | ppl     1.12\n",
            "| epoch   6 |   212/  269 batches | lr 0.004429 | 13.83 ms | loss 0.08728 | ppl     1.09\n",
            "| epoch   6 |   265/  269 batches | lr 0.004429 | 13.72 ms | loss 0.08719 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   6 | time:  4.35s | valid loss 0.27073 | valid ppl     1.31\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   7 |    53/  269 batches | lr 0.004341 | 14.65 ms | loss 0.11754 | ppl     1.12\n",
            "| epoch   7 |   106/  269 batches | lr 0.004341 | 13.94 ms | loss 0.11416 | ppl     1.12\n",
            "| epoch   7 |   159/  269 batches | lr 0.004341 | 13.72 ms | loss 0.11511 | ppl     1.12\n",
            "| epoch   7 |   212/  269 batches | lr 0.004341 | 13.74 ms | loss 0.08535 | ppl     1.09\n",
            "| epoch   7 |   265/  269 batches | lr 0.004341 | 14.01 ms | loss 0.09059 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   7 | time:  4.36s | valid loss 0.17602 | valid ppl     1.19\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   8 |    53/  269 batches | lr 0.004254 | 14.53 ms | loss 0.13470 | ppl     1.14\n",
            "| epoch   8 |   106/  269 batches | lr 0.004254 | 14.15 ms | loss 0.15204 | ppl     1.16\n",
            "| epoch   8 |   159/  269 batches | lr 0.004254 | 13.83 ms | loss 0.12129 | ppl     1.13\n",
            "| epoch   8 |   212/  269 batches | lr 0.004254 | 13.84 ms | loss 0.10309 | ppl     1.11\n",
            "| epoch   8 |   265/  269 batches | lr 0.004254 | 13.92 ms | loss 0.09885 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   8 | time:  4.37s | valid loss 0.14638 | valid ppl     1.16\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   9 |    53/  269 batches | lr 0.004169 | 14.58 ms | loss 0.10752 | ppl     1.11\n",
            "| epoch   9 |   106/  269 batches | lr 0.004169 | 14.03 ms | loss 0.12368 | ppl     1.13\n",
            "| epoch   9 |   159/  269 batches | lr 0.004169 | 14.00 ms | loss 0.12708 | ppl     1.14\n",
            "| epoch   9 |   212/  269 batches | lr 0.004169 | 13.86 ms | loss 0.09800 | ppl     1.10\n",
            "| epoch   9 |   265/  269 batches | lr 0.004169 | 13.95 ms | loss 0.11215 | ppl     1.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   9 | time:  4.38s | valid loss 0.17921 | valid ppl     1.20\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  10 |    53/  269 batches | lr 0.004085 | 14.45 ms | loss 0.11793 | ppl     1.13\n",
            "| epoch  10 |   106/  269 batches | lr 0.004085 | 13.82 ms | loss 0.11934 | ppl     1.13\n",
            "| epoch  10 |   159/  269 batches | lr 0.004085 | 14.00 ms | loss 0.13096 | ppl     1.14\n",
            "| epoch  10 |   212/  269 batches | lr 0.004085 | 14.06 ms | loss 0.10888 | ppl     1.12\n",
            "| epoch  10 |   265/  269 batches | lr 0.004085 | 13.87 ms | loss 0.11908 | ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  10 | time: 10.45s | valid loss 0.09295 | valid ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  11 |    53/  269 batches | lr 0.004004 | 15.05 ms | loss 0.12755 | ppl     1.14\n",
            "| epoch  11 |   106/  269 batches | lr 0.004004 | 13.93 ms | loss 0.12658 | ppl     1.13\n",
            "| epoch  11 |   159/  269 batches | lr 0.004004 | 13.62 ms | loss 0.10638 | ppl     1.11\n",
            "| epoch  11 |   212/  269 batches | lr 0.004004 | 14.11 ms | loss 0.10512 | ppl     1.11\n",
            "| epoch  11 |   265/  269 batches | lr 0.004004 | 14.04 ms | loss 0.11381 | ppl     1.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  11 | time:  4.40s | valid loss 0.12312 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  12 |    53/  269 batches | lr 0.003924 | 14.44 ms | loss 0.11934 | ppl     1.13\n",
            "| epoch  12 |   106/  269 batches | lr 0.003924 | 14.00 ms | loss 0.12429 | ppl     1.13\n",
            "| epoch  12 |   159/  269 batches | lr 0.003924 | 13.76 ms | loss 0.10939 | ppl     1.12\n",
            "| epoch  12 |   212/  269 batches | lr 0.003924 | 13.50 ms | loss 0.10036 | ppl     1.11\n",
            "| epoch  12 |   265/  269 batches | lr 0.003924 | 13.76 ms | loss 0.11643 | ppl     1.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  12 | time:  4.32s | valid loss 0.15584 | valid ppl     1.17\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  13 |    53/  269 batches | lr 0.003845 | 14.11 ms | loss 0.12069 | ppl     1.13\n",
            "| epoch  13 |   106/  269 batches | lr 0.003845 | 13.83 ms | loss 0.15942 | ppl     1.17\n",
            "| epoch  13 |   159/  269 batches | lr 0.003845 | 13.78 ms | loss 0.17675 | ppl     1.19\n",
            "| epoch  13 |   212/  269 batches | lr 0.003845 | 13.70 ms | loss 0.09964 | ppl     1.10\n",
            "| epoch  13 |   265/  269 batches | lr 0.003845 | 13.79 ms | loss 0.11061 | ppl     1.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  13 | time:  4.31s | valid loss 0.12520 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  14 |    53/  269 batches | lr 0.003768 | 14.26 ms | loss 0.13459 | ppl     1.14\n",
            "| epoch  14 |   106/  269 batches | lr 0.003768 | 13.93 ms | loss 0.13091 | ppl     1.14\n",
            "| epoch  14 |   159/  269 batches | lr 0.003768 | 13.90 ms | loss 0.10580 | ppl     1.11\n",
            "| epoch  14 |   212/  269 batches | lr 0.003768 | 14.04 ms | loss 0.09710 | ppl     1.10\n",
            "| epoch  14 |   265/  269 batches | lr 0.003768 | 13.95 ms | loss 0.11197 | ppl     1.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  14 | time:  4.38s | valid loss 0.12932 | valid ppl     1.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  15 |    53/  269 batches | lr 0.003693 | 14.59 ms | loss 0.10676 | ppl     1.11\n",
            "| epoch  15 |   106/  269 batches | lr 0.003693 | 14.30 ms | loss 0.12639 | ppl     1.13\n",
            "| epoch  15 |   159/  269 batches | lr 0.003693 | 13.77 ms | loss 0.16583 | ppl     1.18\n",
            "| epoch  15 |   212/  269 batches | lr 0.003693 | 13.93 ms | loss 0.10340 | ppl     1.11\n",
            "| epoch  15 |   265/  269 batches | lr 0.003693 | 13.97 ms | loss 0.11848 | ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  15 | time:  4.39s | valid loss 0.12301 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  16 |    53/  269 batches | lr 0.003619 | 14.25 ms | loss 0.12937 | ppl     1.14\n",
            "| epoch  16 |   106/  269 batches | lr 0.003619 | 13.93 ms | loss 0.12524 | ppl     1.13\n",
            "| epoch  16 |   159/  269 batches | lr 0.003619 | 13.67 ms | loss 0.10936 | ppl     1.12\n",
            "| epoch  16 |   212/  269 batches | lr 0.003619 | 13.74 ms | loss 0.10246 | ppl     1.11\n",
            "| epoch  16 |   265/  269 batches | lr 0.003619 | 14.11 ms | loss 0.11711 | ppl     1.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  16 | time:  4.35s | valid loss 0.12468 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  17 |    53/  269 batches | lr 0.003547 | 14.44 ms | loss 0.13035 | ppl     1.14\n",
            "| epoch  17 |   106/  269 batches | lr 0.003547 | 13.85 ms | loss 0.13747 | ppl     1.15\n",
            "| epoch  17 |   159/  269 batches | lr 0.003547 | 14.00 ms | loss 0.12548 | ppl     1.13\n",
            "| epoch  17 |   212/  269 batches | lr 0.003547 | 13.94 ms | loss 0.10243 | ppl     1.11\n",
            "| epoch  17 |   265/  269 batches | lr 0.003547 | 13.89 ms | loss 0.11301 | ppl     1.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  17 | time:  4.37s | valid loss 0.12311 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  18 |    53/  269 batches | lr 0.003476 | 14.66 ms | loss 0.12161 | ppl     1.13\n",
            "| epoch  18 |   106/  269 batches | lr 0.003476 | 13.95 ms | loss 0.14264 | ppl     1.15\n",
            "| epoch  18 |   159/  269 batches | lr 0.003476 | 13.69 ms | loss 0.15731 | ppl     1.17\n",
            "| epoch  18 |   212/  269 batches | lr 0.003476 | 13.96 ms | loss 0.09039 | ppl     1.09\n",
            "| epoch  18 |   265/  269 batches | lr 0.003476 | 13.90 ms | loss 0.11017 | ppl     1.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  18 | time:  4.37s | valid loss 0.12791 | valid ppl     1.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  19 |    53/  269 batches | lr 0.003406 | 14.29 ms | loss 0.13516 | ppl     1.14\n",
            "| epoch  19 |   106/  269 batches | lr 0.003406 | 14.13 ms | loss 0.12864 | ppl     1.14\n",
            "| epoch  19 |   159/  269 batches | lr 0.003406 | 13.85 ms | loss 0.10651 | ppl     1.11\n",
            "| epoch  19 |   212/  269 batches | lr 0.003406 | 13.81 ms | loss 0.09795 | ppl     1.10\n",
            "| epoch  19 |   265/  269 batches | lr 0.003406 | 13.84 ms | loss 0.10974 | ppl     1.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  19 | time:  4.35s | valid loss 0.12551 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  20 |    53/  269 batches | lr 0.003338 | 14.21 ms | loss 0.11596 | ppl     1.12\n",
            "| epoch  20 |   106/  269 batches | lr 0.003338 | 13.81 ms | loss 0.13329 | ppl     1.14\n",
            "| epoch  20 |   159/  269 batches | lr 0.003338 | 14.17 ms | loss 0.15817 | ppl     1.17\n",
            "| epoch  20 |   212/  269 batches | lr 0.003338 | 13.99 ms | loss 0.10301 | ppl     1.11\n",
            "| epoch  20 |   265/  269 batches | lr 0.003338 | 14.00 ms | loss 0.11216 | ppl     1.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  20 | time: 10.49s | valid loss 0.09209 | valid ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  21 |    53/  269 batches | lr 0.003271 | 14.95 ms | loss 0.13374 | ppl     1.14\n",
            "| epoch  21 |   106/  269 batches | lr 0.003271 | 14.09 ms | loss 0.13347 | ppl     1.14\n",
            "| epoch  21 |   159/  269 batches | lr 0.003271 | 13.74 ms | loss 0.10522 | ppl     1.11\n",
            "| epoch  21 |   212/  269 batches | lr 0.003271 | 13.81 ms | loss 0.10018 | ppl     1.11\n",
            "| epoch  21 |   265/  269 batches | lr 0.003271 | 13.58 ms | loss 0.10518 | ppl     1.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  21 | time:  4.37s | valid loss 0.12300 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  22 |    53/  269 batches | lr 0.003206 | 14.70 ms | loss 0.11889 | ppl     1.13\n",
            "| epoch  22 |   106/  269 batches | lr 0.003206 | 13.85 ms | loss 0.14227 | ppl     1.15\n",
            "| epoch  22 |   159/  269 batches | lr 0.003206 | 13.89 ms | loss 0.13408 | ppl     1.14\n",
            "| epoch  22 |   212/  269 batches | lr 0.003206 | 13.87 ms | loss 0.08377 | ppl     1.09\n",
            "| epoch  22 |   265/  269 batches | lr 0.003206 | 13.77 ms | loss 0.10352 | ppl     1.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  22 | time:  4.37s | valid loss 0.12633 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  23 |    53/  269 batches | lr 0.003142 | 14.60 ms | loss 0.13863 | ppl     1.15\n",
            "| epoch  23 |   106/  269 batches | lr 0.003142 | 13.86 ms | loss 0.13186 | ppl     1.14\n",
            "| epoch  23 |   159/  269 batches | lr 0.003142 | 14.04 ms | loss 0.12924 | ppl     1.14\n",
            "| epoch  23 |   212/  269 batches | lr 0.003142 | 13.94 ms | loss 0.09853 | ppl     1.10\n",
            "| epoch  23 |   265/  269 batches | lr 0.003142 | 13.96 ms | loss 0.10788 | ppl     1.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  23 | time:  4.38s | valid loss 0.12488 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  24 |    53/  269 batches | lr 0.003079 | 14.17 ms | loss 0.11455 | ppl     1.12\n",
            "| epoch  24 |   106/  269 batches | lr 0.003079 | 13.82 ms | loss 0.13785 | ppl     1.15\n",
            "| epoch  24 |   159/  269 batches | lr 0.003079 | 13.90 ms | loss 0.14974 | ppl     1.16\n",
            "| epoch  24 |   212/  269 batches | lr 0.003079 | 13.81 ms | loss 0.08844 | ppl     1.09\n",
            "| epoch  24 |   265/  269 batches | lr 0.003079 | 13.75 ms | loss 0.11067 | ppl     1.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  24 | time:  4.33s | valid loss 0.12550 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  25 |    53/  269 batches | lr 0.003017 | 14.49 ms | loss 0.13095 | ppl     1.14\n",
            "| epoch  25 |   106/  269 batches | lr 0.003017 | 13.75 ms | loss 0.12846 | ppl     1.14\n",
            "| epoch  25 |   159/  269 batches | lr 0.003017 | 13.86 ms | loss 0.10807 | ppl     1.11\n",
            "| epoch  25 |   212/  269 batches | lr 0.003017 | 13.87 ms | loss 0.10038 | ppl     1.11\n",
            "| epoch  25 |   265/  269 batches | lr 0.003017 | 13.84 ms | loss 0.11198 | ppl     1.12\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  25 | time:  4.36s | valid loss 0.12329 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  26 |    53/  269 batches | lr 0.002957 | 14.62 ms | loss 0.12474 | ppl     1.13\n",
            "| epoch  26 |   106/  269 batches | lr 0.002957 | 13.80 ms | loss 0.13861 | ppl     1.15\n",
            "| epoch  26 |   159/  269 batches | lr 0.002957 | 13.74 ms | loss 0.13325 | ppl     1.14\n",
            "| epoch  26 |   212/  269 batches | lr 0.002957 | 13.87 ms | loss 0.09258 | ppl     1.10\n",
            "| epoch  26 |   265/  269 batches | lr 0.002957 | 13.77 ms | loss 0.10574 | ppl     1.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  26 | time:  4.35s | valid loss 0.12439 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  27 |    53/  269 batches | lr 0.002898 | 14.52 ms | loss 0.12741 | ppl     1.14\n",
            "| epoch  27 |   106/  269 batches | lr 0.002898 | 14.00 ms | loss 0.13491 | ppl     1.14\n",
            "| epoch  27 |   159/  269 batches | lr 0.002898 | 14.01 ms | loss 0.11630 | ppl     1.12\n",
            "| epoch  27 |   212/  269 batches | lr 0.002898 | 14.19 ms | loss 0.09633 | ppl     1.10\n",
            "| epoch  27 |   265/  269 batches | lr 0.002898 | 14.02 ms | loss 0.10588 | ppl     1.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  27 | time:  4.40s | valid loss 0.12609 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  28 |    53/  269 batches | lr 0.002840 | 14.56 ms | loss 0.13091 | ppl     1.14\n",
            "| epoch  28 |   106/  269 batches | lr 0.002840 | 14.06 ms | loss 0.13716 | ppl     1.15\n",
            "| epoch  28 |   159/  269 batches | lr 0.002840 | 13.91 ms | loss 0.11883 | ppl     1.13\n",
            "| epoch  28 |   212/  269 batches | lr 0.002840 | 14.00 ms | loss 0.09101 | ppl     1.10\n",
            "| epoch  28 |   265/  269 batches | lr 0.002840 | 13.95 ms | loss 0.10557 | ppl     1.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  28 | time:  4.39s | valid loss 0.12667 | valid ppl     1.14\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  29 |    53/  269 batches | lr 0.002783 | 14.33 ms | loss 0.13528 | ppl     1.14\n",
            "| epoch  29 |   106/  269 batches | lr 0.002783 | 13.85 ms | loss 0.12731 | ppl     1.14\n",
            "| epoch  29 |   159/  269 batches | lr 0.002783 | 13.99 ms | loss 0.11135 | ppl     1.12\n",
            "| epoch  29 |   212/  269 batches | lr 0.002783 | 13.82 ms | loss 0.09192 | ppl     1.10\n",
            "| epoch  29 |   265/  269 batches | lr 0.002783 | 14.14 ms | loss 0.10276 | ppl     1.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  29 | time:  4.37s | valid loss 0.12354 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  30 |    53/  269 batches | lr 0.002727 | 14.45 ms | loss 0.12481 | ppl     1.13\n",
            "| epoch  30 |   106/  269 batches | lr 0.002727 | 13.95 ms | loss 0.13438 | ppl     1.14\n",
            "| epoch  30 |   159/  269 batches | lr 0.002727 | 13.83 ms | loss 0.11415 | ppl     1.12\n",
            "| epoch  30 |   212/  269 batches | lr 0.002727 | 13.82 ms | loss 0.08668 | ppl     1.09\n",
            "| epoch  30 |   265/  269 batches | lr 0.002727 | 13.80 ms | loss 0.10226 | ppl     1.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  30 | time: 10.66s | valid loss 0.09450 | valid ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  31 |    53/  269 batches | lr 0.002673 | 15.25 ms | loss 0.13249 | ppl     1.14\n",
            "| epoch  31 |   106/  269 batches | lr 0.002673 | 13.95 ms | loss 0.12269 | ppl     1.13\n",
            "| epoch  31 |   159/  269 batches | lr 0.002673 | 14.01 ms | loss 0.10660 | ppl     1.11\n",
            "| epoch  31 |   212/  269 batches | lr 0.002673 | 14.00 ms | loss 0.08859 | ppl     1.09\n",
            "| epoch  31 |   265/  269 batches | lr 0.002673 | 13.82 ms | loss 0.10111 | ppl     1.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  31 | time:  4.42s | valid loss 0.12367 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  32 |    53/  269 batches | lr 0.002619 | 14.68 ms | loss 0.12544 | ppl     1.13\n",
            "| epoch  32 |   106/  269 batches | lr 0.002619 | 14.11 ms | loss 0.13401 | ppl     1.14\n",
            "| epoch  32 |   159/  269 batches | lr 0.002619 | 14.07 ms | loss 0.11110 | ppl     1.12\n",
            "| epoch  32 |   212/  269 batches | lr 0.002619 | 13.88 ms | loss 0.09097 | ppl     1.10\n",
            "| epoch  32 |   265/  269 batches | lr 0.002619 | 13.81 ms | loss 0.10334 | ppl     1.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  32 | time:  4.39s | valid loss 0.12631 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  33 |    53/  269 batches | lr 0.002567 | 14.25 ms | loss 0.13292 | ppl     1.14\n",
            "| epoch  33 |   106/  269 batches | lr 0.002567 | 13.68 ms | loss 0.12958 | ppl     1.14\n",
            "| epoch  33 |   159/  269 batches | lr 0.002567 | 13.70 ms | loss 0.11041 | ppl     1.12\n",
            "| epoch  33 |   212/  269 batches | lr 0.002567 | 13.84 ms | loss 0.08656 | ppl     1.09\n",
            "| epoch  33 |   265/  269 batches | lr 0.002567 | 14.03 ms | loss 0.10000 | ppl     1.11\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  33 | time:  4.34s | valid loss 0.12411 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  34 |    53/  269 batches | lr 0.002516 | 14.53 ms | loss 0.12541 | ppl     1.13\n",
            "| epoch  34 |   106/  269 batches | lr 0.002516 | 13.89 ms | loss 0.13084 | ppl     1.14\n",
            "| epoch  34 |   159/  269 batches | lr 0.002516 | 13.86 ms | loss 0.11143 | ppl     1.12\n",
            "| epoch  34 |   212/  269 batches | lr 0.002516 | 13.99 ms | loss 0.08740 | ppl     1.09\n",
            "| epoch  34 |   265/  269 batches | lr 0.002516 | 14.03 ms | loss 0.09915 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  34 | time:  4.38s | valid loss 0.12527 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  35 |    53/  269 batches | lr 0.002465 | 14.61 ms | loss 0.12790 | ppl     1.14\n",
            "| epoch  35 |   106/  269 batches | lr 0.002465 | 13.96 ms | loss 0.12975 | ppl     1.14\n",
            "| epoch  35 |   159/  269 batches | lr 0.002465 | 13.97 ms | loss 0.10881 | ppl     1.11\n",
            "| epoch  35 |   212/  269 batches | lr 0.002465 | 13.88 ms | loss 0.08555 | ppl     1.09\n",
            "| epoch  35 |   265/  269 batches | lr 0.002465 | 13.87 ms | loss 0.09753 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  35 | time:  4.38s | valid loss 0.12631 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  36 |    53/  269 batches | lr 0.002416 | 14.55 ms | loss 0.13037 | ppl     1.14\n",
            "| epoch  36 |   106/  269 batches | lr 0.002416 | 13.84 ms | loss 0.12173 | ppl     1.13\n",
            "| epoch  36 |   159/  269 batches | lr 0.002416 | 14.00 ms | loss 0.10656 | ppl     1.11\n",
            "| epoch  36 |   212/  269 batches | lr 0.002416 | 13.96 ms | loss 0.08449 | ppl     1.09\n",
            "| epoch  36 |   265/  269 batches | lr 0.002416 | 14.12 ms | loss 0.09616 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  36 | time:  4.39s | valid loss 0.12457 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  37 |    53/  269 batches | lr 0.002368 | 14.54 ms | loss 0.12673 | ppl     1.14\n",
            "| epoch  37 |   106/  269 batches | lr 0.002368 | 14.17 ms | loss 0.12564 | ppl     1.13\n",
            "| epoch  37 |   159/  269 batches | lr 0.002368 | 13.99 ms | loss 0.10568 | ppl     1.11\n",
            "| epoch  37 |   212/  269 batches | lr 0.002368 | 14.04 ms | loss 0.08356 | ppl     1.09\n",
            "| epoch  37 |   265/  269 batches | lr 0.002368 | 13.93 ms | loss 0.09615 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  37 | time:  4.40s | valid loss 0.12394 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  38 |    53/  269 batches | lr 0.002320 | 14.41 ms | loss 0.12522 | ppl     1.13\n",
            "| epoch  38 |   106/  269 batches | lr 0.002320 | 14.13 ms | loss 0.12761 | ppl     1.14\n",
            "| epoch  38 |   159/  269 batches | lr 0.002320 | 13.89 ms | loss 0.10709 | ppl     1.11\n",
            "| epoch  38 |   212/  269 batches | lr 0.002320 | 13.88 ms | loss 0.08402 | ppl     1.09\n",
            "| epoch  38 |   265/  269 batches | lr 0.002320 | 14.16 ms | loss 0.09661 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  38 | time:  4.40s | valid loss 0.12568 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  39 |    53/  269 batches | lr 0.002274 | 14.39 ms | loss 0.12964 | ppl     1.14\n",
            "| epoch  39 |   106/  269 batches | lr 0.002274 | 14.01 ms | loss 0.12203 | ppl     1.13\n",
            "| epoch  39 |   159/  269 batches | lr 0.002274 | 14.04 ms | loss 0.10552 | ppl     1.11\n",
            "| epoch  39 |   212/  269 batches | lr 0.002274 | 13.85 ms | loss 0.08350 | ppl     1.09\n",
            "| epoch  39 |   265/  269 batches | lr 0.002274 | 13.94 ms | loss 0.09530 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  39 | time:  4.38s | valid loss 0.12448 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  40 |    53/  269 batches | lr 0.002229 | 14.70 ms | loss 0.12626 | ppl     1.13\n",
            "| epoch  40 |   106/  269 batches | lr 0.002229 | 13.98 ms | loss 0.12262 | ppl     1.13\n",
            "| epoch  40 |   159/  269 batches | lr 0.002229 | 13.86 ms | loss 0.10538 | ppl     1.11\n",
            "| epoch  40 |   212/  269 batches | lr 0.002229 | 14.02 ms | loss 0.08504 | ppl     1.09\n",
            "| epoch  40 |   265/  269 batches | lr 0.002229 | 13.72 ms | loss 0.09540 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  40 | time: 10.58s | valid loss 0.09265 | valid ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  41 |    53/  269 batches | lr 0.002184 | 15.47 ms | loss 0.12563 | ppl     1.13\n",
            "| epoch  41 |   106/  269 batches | lr 0.002184 | 14.27 ms | loss 0.12459 | ppl     1.13\n",
            "| epoch  41 |   159/  269 batches | lr 0.002184 | 14.11 ms | loss 0.10656 | ppl     1.11\n",
            "| epoch  41 |   212/  269 batches | lr 0.002184 | 13.83 ms | loss 0.08355 | ppl     1.09\n",
            "| epoch  41 |   265/  269 batches | lr 0.002184 | 13.99 ms | loss 0.09565 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  41 | time:  4.45s | valid loss 0.12574 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  42 |    53/  269 batches | lr 0.002140 | 14.50 ms | loss 0.12886 | ppl     1.14\n",
            "| epoch  42 |   106/  269 batches | lr 0.002140 | 13.81 ms | loss 0.12037 | ppl     1.13\n",
            "| epoch  42 |   159/  269 batches | lr 0.002140 | 14.04 ms | loss 0.10445 | ppl     1.11\n",
            "| epoch  42 |   212/  269 batches | lr 0.002140 | 14.02 ms | loss 0.08211 | ppl     1.09\n",
            "| epoch  42 |   265/  269 batches | lr 0.002140 | 13.81 ms | loss 0.09303 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  42 | time:  4.38s | valid loss 0.12368 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  43 |    53/  269 batches | lr 0.002097 | 14.70 ms | loss 0.12117 | ppl     1.13\n",
            "| epoch  43 |   106/  269 batches | lr 0.002097 | 13.98 ms | loss 0.12509 | ppl     1.13\n",
            "| epoch  43 |   159/  269 batches | lr 0.002097 | 14.01 ms | loss 0.10649 | ppl     1.11\n",
            "| epoch  43 |   212/  269 batches | lr 0.002097 | 13.92 ms | loss 0.08502 | ppl     1.09\n",
            "| epoch  43 |   265/  269 batches | lr 0.002097 | 14.27 ms | loss 0.09368 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  43 | time:  4.42s | valid loss 0.12542 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  44 |    53/  269 batches | lr 0.002055 | 14.35 ms | loss 0.12739 | ppl     1.14\n",
            "| epoch  44 |   106/  269 batches | lr 0.002055 | 14.14 ms | loss 0.12186 | ppl     1.13\n",
            "| epoch  44 |   159/  269 batches | lr 0.002055 | 14.12 ms | loss 0.10415 | ppl     1.11\n",
            "| epoch  44 |   212/  269 batches | lr 0.002055 | 13.81 ms | loss 0.07752 | ppl     1.08\n",
            "| epoch  44 |   265/  269 batches | lr 0.002055 | 13.65 ms | loss 0.09111 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  44 | time:  4.36s | valid loss 0.12527 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  45 |    53/  269 batches | lr 0.002014 | 14.19 ms | loss 0.12557 | ppl     1.13\n",
            "| epoch  45 |   106/  269 batches | lr 0.002014 | 13.63 ms | loss 0.11182 | ppl     1.12\n",
            "| epoch  45 |   159/  269 batches | lr 0.002014 | 13.75 ms | loss 0.10144 | ppl     1.11\n",
            "| epoch  45 |   212/  269 batches | lr 0.002014 | 13.71 ms | loss 0.08070 | ppl     1.08\n",
            "| epoch  45 |   265/  269 batches | lr 0.002014 | 13.87 ms | loss 0.09148 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  45 | time:  4.32s | valid loss 0.12351 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  46 |    53/  269 batches | lr 0.001974 | 14.37 ms | loss 0.12129 | ppl     1.13\n",
            "| epoch  46 |   106/  269 batches | lr 0.001974 | 13.93 ms | loss 0.12377 | ppl     1.13\n",
            "| epoch  46 |   159/  269 batches | lr 0.001974 | 13.98 ms | loss 0.10569 | ppl     1.11\n",
            "| epoch  46 |   212/  269 batches | lr 0.001974 | 14.14 ms | loss 0.08229 | ppl     1.09\n",
            "| epoch  46 |   265/  269 batches | lr 0.001974 | 14.12 ms | loss 0.09421 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  46 | time:  4.39s | valid loss 0.12564 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  47 |    53/  269 batches | lr 0.001935 | 14.48 ms | loss 0.12925 | ppl     1.14\n",
            "| epoch  47 |   106/  269 batches | lr 0.001935 | 14.04 ms | loss 0.11621 | ppl     1.12\n",
            "| epoch  47 |   159/  269 batches | lr 0.001935 | 14.03 ms | loss 0.10463 | ppl     1.11\n",
            "| epoch  47 |   212/  269 batches | lr 0.001935 | 13.74 ms | loss 0.08097 | ppl     1.08\n",
            "| epoch  47 |   265/  269 batches | lr 0.001935 | 14.07 ms | loss 0.09259 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  47 | time:  4.38s | valid loss 0.12437 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  48 |    53/  269 batches | lr 0.001896 | 14.43 ms | loss 0.12543 | ppl     1.13\n",
            "| epoch  48 |   106/  269 batches | lr 0.001896 | 13.94 ms | loss 0.11550 | ppl     1.12\n",
            "| epoch  48 |   159/  269 batches | lr 0.001896 | 14.13 ms | loss 0.10059 | ppl     1.11\n",
            "| epoch  48 |   212/  269 batches | lr 0.001896 | 13.91 ms | loss 0.07872 | ppl     1.08\n",
            "| epoch  48 |   265/  269 batches | lr 0.001896 | 13.97 ms | loss 0.09097 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  48 | time:  4.38s | valid loss 0.12352 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  49 |    53/  269 batches | lr 0.001858 | 14.49 ms | loss 0.12226 | ppl     1.13\n",
            "| epoch  49 |   106/  269 batches | lr 0.001858 | 13.94 ms | loss 0.11958 | ppl     1.13\n",
            "| epoch  49 |   159/  269 batches | lr 0.001858 | 13.97 ms | loss 0.10383 | ppl     1.11\n",
            "| epoch  49 |   212/  269 batches | lr 0.001858 | 14.20 ms | loss 0.07971 | ppl     1.08\n",
            "| epoch  49 |   265/  269 batches | lr 0.001858 | 13.85 ms | loss 0.09213 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  49 | time:  4.40s | valid loss 0.12536 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  50 |    53/  269 batches | lr 0.001821 | 14.54 ms | loss 0.12666 | ppl     1.14\n",
            "| epoch  50 |   106/  269 batches | lr 0.001821 | 14.12 ms | loss 0.11234 | ppl     1.12\n",
            "| epoch  50 |   159/  269 batches | lr 0.001821 | 13.94 ms | loss 0.10113 | ppl     1.11\n",
            "| epoch  50 |   212/  269 batches | lr 0.001821 | 14.20 ms | loss 0.07856 | ppl     1.08\n",
            "| epoch  50 |   265/  269 batches | lr 0.001821 | 13.97 ms | loss 0.09146 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  50 | time: 10.58s | valid loss 0.09201 | valid ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  51 |    53/  269 batches | lr 0.001784 | 15.10 ms | loss 0.12534 | ppl     1.13\n",
            "| epoch  51 |   106/  269 batches | lr 0.001784 | 14.12 ms | loss 0.11286 | ppl     1.12\n",
            "| epoch  51 |   159/  269 batches | lr 0.001784 | 14.01 ms | loss 0.10089 | ppl     1.11\n",
            "| epoch  51 |   212/  269 batches | lr 0.001784 | 13.92 ms | loss 0.07858 | ppl     1.08\n",
            "| epoch  51 |   265/  269 batches | lr 0.001784 | 13.98 ms | loss 0.09096 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  51 | time:  4.43s | valid loss 0.12371 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  52 |    53/  269 batches | lr 0.001749 | 15.02 ms | loss 0.12404 | ppl     1.13\n",
            "| epoch  52 |   106/  269 batches | lr 0.001749 | 13.86 ms | loss 0.11534 | ppl     1.12\n",
            "| epoch  52 |   159/  269 batches | lr 0.001749 | 14.02 ms | loss 0.10190 | ppl     1.11\n",
            "| epoch  52 |   212/  269 batches | lr 0.001749 | 13.92 ms | loss 0.07938 | ppl     1.08\n",
            "| epoch  52 |   265/  269 batches | lr 0.001749 | 13.86 ms | loss 0.09210 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  52 | time:  4.40s | valid loss 0.12423 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  53 |    53/  269 batches | lr 0.001714 | 14.47 ms | loss 0.12495 | ppl     1.13\n",
            "| epoch  53 |   106/  269 batches | lr 0.001714 | 13.95 ms | loss 0.11645 | ppl     1.12\n",
            "| epoch  53 |   159/  269 batches | lr 0.001714 | 13.99 ms | loss 0.10158 | ppl     1.11\n",
            "| epoch  53 |   212/  269 batches | lr 0.001714 | 13.98 ms | loss 0.07938 | ppl     1.08\n",
            "| epoch  53 |   265/  269 batches | lr 0.001714 | 13.74 ms | loss 0.09021 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  53 | time:  4.37s | valid loss 0.12378 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  54 |    53/  269 batches | lr 0.001679 | 14.54 ms | loss 0.12387 | ppl     1.13\n",
            "| epoch  54 |   106/  269 batches | lr 0.001679 | 13.79 ms | loss 0.11401 | ppl     1.12\n",
            "| epoch  54 |   159/  269 batches | lr 0.001679 | 13.99 ms | loss 0.10070 | ppl     1.11\n",
            "| epoch  54 |   212/  269 batches | lr 0.001679 | 13.89 ms | loss 0.07538 | ppl     1.08\n",
            "| epoch  54 |   265/  269 batches | lr 0.001679 | 13.88 ms | loss 0.08925 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  54 | time:  4.37s | valid loss 0.12406 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  55 |    53/  269 batches | lr 0.001646 | 14.45 ms | loss 0.12223 | ppl     1.13\n",
            "| epoch  55 |   106/  269 batches | lr 0.001646 | 14.07 ms | loss 0.10507 | ppl     1.11\n",
            "| epoch  55 |   159/  269 batches | lr 0.001646 | 13.97 ms | loss 0.09909 | ppl     1.10\n",
            "| epoch  55 |   212/  269 batches | lr 0.001646 | 13.88 ms | loss 0.07792 | ppl     1.08\n",
            "| epoch  55 |   265/  269 batches | lr 0.001646 | 14.01 ms | loss 0.09096 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  55 | time:  4.38s | valid loss 0.12374 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  56 |    53/  269 batches | lr 0.001613 | 14.35 ms | loss 0.12424 | ppl     1.13\n",
            "| epoch  56 |   106/  269 batches | lr 0.001613 | 13.97 ms | loss 0.11480 | ppl     1.12\n",
            "| epoch  56 |   159/  269 batches | lr 0.001613 | 14.01 ms | loss 0.10054 | ppl     1.11\n",
            "| epoch  56 |   212/  269 batches | lr 0.001613 | 14.03 ms | loss 0.07943 | ppl     1.08\n",
            "| epoch  56 |   265/  269 batches | lr 0.001613 | 14.02 ms | loss 0.09104 | ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  56 | time:  4.39s | valid loss 0.12363 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  57 |    53/  269 batches | lr 0.001581 | 14.56 ms | loss 0.12410 | ppl     1.13\n",
            "| epoch  57 |   106/  269 batches | lr 0.001581 | 13.80 ms | loss 0.11558 | ppl     1.12\n",
            "| epoch  57 |   159/  269 batches | lr 0.001581 | 14.23 ms | loss 0.10138 | ppl     1.11\n",
            "| epoch  57 |   212/  269 batches | lr 0.001581 | 14.01 ms | loss 0.07742 | ppl     1.08\n",
            "| epoch  57 |   265/  269 batches | lr 0.001581 | 13.88 ms | loss 0.08964 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  57 | time:  4.39s | valid loss 0.12411 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  58 |    53/  269 batches | lr 0.001549 | 14.37 ms | loss 0.12362 | ppl     1.13\n",
            "| epoch  58 |   106/  269 batches | lr 0.001549 | 14.16 ms | loss 0.10545 | ppl     1.11\n",
            "| epoch  58 |   159/  269 batches | lr 0.001549 | 13.88 ms | loss 0.09932 | ppl     1.10\n",
            "| epoch  58 |   212/  269 batches | lr 0.001549 | 14.06 ms | loss 0.07716 | ppl     1.08\n",
            "| epoch  58 |   265/  269 batches | lr 0.001549 | 13.98 ms | loss 0.08939 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  58 | time:  4.39s | valid loss 0.12357 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  59 |    53/  269 batches | lr 0.001518 | 14.22 ms | loss 0.12223 | ppl     1.13\n",
            "| epoch  59 |   106/  269 batches | lr 0.001518 | 14.11 ms | loss 0.11152 | ppl     1.12\n",
            "| epoch  59 |   159/  269 batches | lr 0.001518 | 13.94 ms | loss 0.09974 | ppl     1.10\n",
            "| epoch  59 |   212/  269 batches | lr 0.001518 | 13.69 ms | loss 0.07633 | ppl     1.08\n",
            "| epoch  59 |   265/  269 batches | lr 0.001518 | 13.97 ms | loss 0.08906 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  59 | time:  4.36s | valid loss 0.12369 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  60 |    53/  269 batches | lr 0.001488 | 14.44 ms | loss 0.12277 | ppl     1.13\n",
            "| epoch  60 |   106/  269 batches | lr 0.001488 | 14.00 ms | loss 0.10899 | ppl     1.12\n",
            "| epoch  60 |   159/  269 batches | lr 0.001488 | 14.13 ms | loss 0.09942 | ppl     1.10\n",
            "| epoch  60 |   212/  269 batches | lr 0.001488 | 14.04 ms | loss 0.07616 | ppl     1.08\n",
            "| epoch  60 |   265/  269 batches | lr 0.001488 | 13.97 ms | loss 0.08900 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  60 | time: 10.77s | valid loss 0.09190 | valid ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  61 |    53/  269 batches | lr 0.001458 | 15.32 ms | loss 0.12237 | ppl     1.13\n",
            "| epoch  61 |   106/  269 batches | lr 0.001458 | 14.03 ms | loss 0.10893 | ppl     1.12\n",
            "| epoch  61 |   159/  269 batches | lr 0.001458 | 14.20 ms | loss 0.09957 | ppl     1.10\n",
            "| epoch  61 |   212/  269 batches | lr 0.001458 | 13.92 ms | loss 0.07747 | ppl     1.08\n",
            "| epoch  61 |   265/  269 batches | lr 0.001458 | 13.89 ms | loss 0.08967 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  61 | time:  4.44s | valid loss 0.12354 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  62 |    53/  269 batches | lr 0.001429 | 14.81 ms | loss 0.12226 | ppl     1.13\n",
            "| epoch  62 |   106/  269 batches | lr 0.001429 | 13.82 ms | loss 0.11399 | ppl     1.12\n",
            "| epoch  62 |   159/  269 batches | lr 0.001429 | 14.02 ms | loss 0.10002 | ppl     1.11\n",
            "| epoch  62 |   212/  269 batches | lr 0.001429 | 13.90 ms | loss 0.07664 | ppl     1.08\n",
            "| epoch  62 |   265/  269 batches | lr 0.001429 | 14.06 ms | loss 0.08886 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  62 | time:  4.40s | valid loss 0.12373 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  63 |    53/  269 batches | lr 0.001400 | 14.71 ms | loss 0.12313 | ppl     1.13\n",
            "| epoch  63 |   106/  269 batches | lr 0.001400 | 13.93 ms | loss 0.10621 | ppl     1.11\n",
            "| epoch  63 |   159/  269 batches | lr 0.001400 | 13.97 ms | loss 0.09876 | ppl     1.10\n",
            "| epoch  63 |   212/  269 batches | lr 0.001400 | 14.19 ms | loss 0.07445 | ppl     1.08\n",
            "| epoch  63 |   265/  269 batches | lr 0.001400 | 13.96 ms | loss 0.08820 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  63 | time:  4.41s | valid loss 0.12353 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  64 |    53/  269 batches | lr 0.001372 | 14.22 ms | loss 0.11977 | ppl     1.13\n",
            "| epoch  64 |   106/  269 batches | lr 0.001372 | 14.00 ms | loss 0.10390 | ppl     1.11\n",
            "| epoch  64 |   159/  269 batches | lr 0.001372 | 13.72 ms | loss 0.09797 | ppl     1.10\n",
            "| epoch  64 |   212/  269 batches | lr 0.001372 | 13.47 ms | loss 0.07584 | ppl     1.08\n",
            "| epoch  64 |   265/  269 batches | lr 0.001372 | 14.11 ms | loss 0.08897 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  64 | time:  4.34s | valid loss 0.12328 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  65 |    53/  269 batches | lr 0.001345 | 14.46 ms | loss 0.12145 | ppl     1.13\n",
            "| epoch  65 |   106/  269 batches | lr 0.001345 | 13.96 ms | loss 0.11145 | ppl     1.12\n",
            "| epoch  65 |   159/  269 batches | lr 0.001345 | 14.00 ms | loss 0.09918 | ppl     1.10\n",
            "| epoch  65 |   212/  269 batches | lr 0.001345 | 13.92 ms | loss 0.07741 | ppl     1.08\n",
            "| epoch  65 |   265/  269 batches | lr 0.001345 | 13.85 ms | loss 0.08935 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  65 | time:  4.38s | valid loss 0.12342 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  66 |    53/  269 batches | lr 0.001318 | 14.52 ms | loss 0.12338 | ppl     1.13\n",
            "| epoch  66 |   106/  269 batches | lr 0.001318 | 13.81 ms | loss 0.10963 | ppl     1.12\n",
            "| epoch  66 |   159/  269 batches | lr 0.001318 | 13.83 ms | loss 0.09953 | ppl     1.10\n",
            "| epoch  66 |   212/  269 batches | lr 0.001318 | 14.03 ms | loss 0.07497 | ppl     1.08\n",
            "| epoch  66 |   265/  269 batches | lr 0.001318 | 13.89 ms | loss 0.08820 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  66 | time:  4.37s | valid loss 0.12371 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  67 |    53/  269 batches | lr 0.001292 | 14.56 ms | loss 0.12048 | ppl     1.13\n",
            "| epoch  67 |   106/  269 batches | lr 0.001292 | 14.05 ms | loss 0.10288 | ppl     1.11\n",
            "| epoch  67 |   159/  269 batches | lr 0.001292 | 13.88 ms | loss 0.09805 | ppl     1.10\n",
            "| epoch  67 |   212/  269 batches | lr 0.001292 | 13.93 ms | loss 0.07464 | ppl     1.08\n",
            "| epoch  67 |   265/  269 batches | lr 0.001292 | 14.10 ms | loss 0.08826 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  67 | time:  4.39s | valid loss 0.12343 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  68 |    53/  269 batches | lr 0.001266 | 14.32 ms | loss 0.11904 | ppl     1.13\n",
            "| epoch  68 |   106/  269 batches | lr 0.001266 | 14.40 ms | loss 0.10440 | ppl     1.11\n",
            "| epoch  68 |   159/  269 batches | lr 0.001266 | 14.12 ms | loss 0.09792 | ppl     1.10\n",
            "| epoch  68 |   212/  269 batches | lr 0.001266 | 13.87 ms | loss 0.07570 | ppl     1.08\n",
            "| epoch  68 |   265/  269 batches | lr 0.001266 | 13.90 ms | loss 0.08866 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  68 | time:  4.39s | valid loss 0.12327 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  69 |    53/  269 batches | lr 0.001240 | 14.53 ms | loss 0.12139 | ppl     1.13\n",
            "| epoch  69 |   106/  269 batches | lr 0.001240 | 13.85 ms | loss 0.10671 | ppl     1.11\n",
            "| epoch  69 |   159/  269 batches | lr 0.001240 | 14.05 ms | loss 0.09817 | ppl     1.10\n",
            "| epoch  69 |   212/  269 batches | lr 0.001240 | 14.17 ms | loss 0.07547 | ppl     1.08\n",
            "| epoch  69 |   265/  269 batches | lr 0.001240 | 13.95 ms | loss 0.08873 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  69 | time:  4.40s | valid loss 0.12343 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  70 |    53/  269 batches | lr 0.001216 | 14.45 ms | loss 0.12206 | ppl     1.13\n",
            "| epoch  70 |   106/  269 batches | lr 0.001216 | 13.98 ms | loss 0.10692 | ppl     1.11\n",
            "| epoch  70 |   159/  269 batches | lr 0.001216 | 13.92 ms | loss 0.09861 | ppl     1.10\n",
            "| epoch  70 |   212/  269 batches | lr 0.001216 | 14.00 ms | loss 0.07553 | ppl     1.08\n",
            "| epoch  70 |   265/  269 batches | lr 0.001216 | 13.88 ms | loss 0.08842 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  70 | time: 10.68s | valid loss 0.09185 | valid ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  71 |    53/  269 batches | lr 0.001191 | 15.05 ms | loss 0.12224 | ppl     1.13\n",
            "| epoch  71 |   106/  269 batches | lr 0.001191 | 13.85 ms | loss 0.10391 | ppl     1.11\n",
            "| epoch  71 |   159/  269 batches | lr 0.001191 | 14.18 ms | loss 0.09789 | ppl     1.10\n",
            "| epoch  71 |   212/  269 batches | lr 0.001191 | 13.99 ms | loss 0.07416 | ppl     1.08\n",
            "| epoch  71 |   265/  269 batches | lr 0.001191 | 13.88 ms | loss 0.08806 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  71 | time:  4.41s | valid loss 0.12338 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  72 |    53/  269 batches | lr 0.001167 | 14.57 ms | loss 0.11855 | ppl     1.13\n",
            "| epoch  72 |   106/  269 batches | lr 0.001167 | 13.89 ms | loss 0.10168 | ppl     1.11\n",
            "| epoch  72 |   159/  269 batches | lr 0.001167 | 14.22 ms | loss 0.09682 | ppl     1.10\n",
            "| epoch  72 |   212/  269 batches | lr 0.001167 | 13.83 ms | loss 0.07402 | ppl     1.08\n",
            "| epoch  72 |   265/  269 batches | lr 0.001167 | 13.87 ms | loss 0.08807 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  72 | time:  4.38s | valid loss 0.12315 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  73 |    53/  269 batches | lr 0.001144 | 14.41 ms | loss 0.11908 | ppl     1.13\n",
            "| epoch  73 |   106/  269 batches | lr 0.001144 | 14.19 ms | loss 0.10537 | ppl     1.11\n",
            "| epoch  73 |   159/  269 batches | lr 0.001144 | 14.05 ms | loss 0.09759 | ppl     1.10\n",
            "| epoch  73 |   212/  269 batches | lr 0.001144 | 14.12 ms | loss 0.07569 | ppl     1.08\n",
            "| epoch  73 |   265/  269 batches | lr 0.001144 | 13.83 ms | loss 0.08874 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  73 | time:  4.39s | valid loss 0.12324 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  74 |    53/  269 batches | lr 0.001121 | 14.53 ms | loss 0.12149 | ppl     1.13\n",
            "| epoch  74 |   106/  269 batches | lr 0.001121 | 13.90 ms | loss 0.10817 | ppl     1.11\n",
            "| epoch  74 |   159/  269 batches | lr 0.001121 | 13.94 ms | loss 0.09833 | ppl     1.10\n",
            "| epoch  74 |   212/  269 batches | lr 0.001121 | 13.85 ms | loss 0.07457 | ppl     1.08\n",
            "| epoch  74 |   265/  269 batches | lr 0.001121 | 14.08 ms | loss 0.08786 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  74 | time:  4.38s | valid loss 0.12338 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  75 |    53/  269 batches | lr 0.001099 | 14.48 ms | loss 0.11880 | ppl     1.13\n",
            "| epoch  75 |   106/  269 batches | lr 0.001099 | 13.95 ms | loss 0.09984 | ppl     1.10\n",
            "| epoch  75 |   159/  269 batches | lr 0.001099 | 13.89 ms | loss 0.09662 | ppl     1.10\n",
            "| epoch  75 |   212/  269 batches | lr 0.001099 | 13.88 ms | loss 0.07336 | ppl     1.08\n",
            "| epoch  75 |   265/  269 batches | lr 0.001099 | 13.91 ms | loss 0.08782 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  75 | time:  4.37s | valid loss 0.12318 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  76 |    53/  269 batches | lr 0.001077 | 14.68 ms | loss 0.11776 | ppl     1.12\n",
            "| epoch  76 |   106/  269 batches | lr 0.001077 | 13.80 ms | loss 0.10202 | ppl     1.11\n",
            "| epoch  76 |   159/  269 batches | lr 0.001077 | 14.21 ms | loss 0.09691 | ppl     1.10\n",
            "| epoch  76 |   212/  269 batches | lr 0.001077 | 13.94 ms | loss 0.07487 | ppl     1.08\n",
            "| epoch  76 |   265/  269 batches | lr 0.001077 | 13.84 ms | loss 0.08876 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  76 | time:  4.39s | valid loss 0.12327 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  77 |    53/  269 batches | lr 0.001055 | 14.77 ms | loss 0.12059 | ppl     1.13\n",
            "| epoch  77 |   106/  269 batches | lr 0.001055 | 14.02 ms | loss 0.10432 | ppl     1.11\n",
            "| epoch  77 |   159/  269 batches | lr 0.001055 | 14.09 ms | loss 0.09694 | ppl     1.10\n",
            "| epoch  77 |   212/  269 batches | lr 0.001055 | 13.83 ms | loss 0.07473 | ppl     1.08\n",
            "| epoch  77 |   265/  269 batches | lr 0.001055 | 13.91 ms | loss 0.08847 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  77 | time:  4.40s | valid loss 0.12318 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  78 |    53/  269 batches | lr 0.001034 | 14.32 ms | loss 0.12101 | ppl     1.13\n",
            "| epoch  78 |   106/  269 batches | lr 0.001034 | 14.11 ms | loss 0.10315 | ppl     1.11\n",
            "| epoch  78 |   159/  269 batches | lr 0.001034 | 13.83 ms | loss 0.09703 | ppl     1.10\n",
            "| epoch  78 |   212/  269 batches | lr 0.001034 | 13.85 ms | loss 0.07420 | ppl     1.08\n",
            "| epoch  78 |   265/  269 batches | lr 0.001034 | 13.92 ms | loss 0.08787 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  78 | time:  4.37s | valid loss 0.12321 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  79 |    53/  269 batches | lr 0.001014 | 14.37 ms | loss 0.11904 | ppl     1.13\n",
            "| epoch  79 |   106/  269 batches | lr 0.001014 | 13.80 ms | loss 0.10154 | ppl     1.11\n",
            "| epoch  79 |   159/  269 batches | lr 0.001014 | 13.95 ms | loss 0.09675 | ppl     1.10\n",
            "| epoch  79 |   212/  269 batches | lr 0.001014 | 13.94 ms | loss 0.07365 | ppl     1.08\n",
            "| epoch  79 |   265/  269 batches | lr 0.001014 | 13.88 ms | loss 0.08778 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  79 | time:  4.36s | valid loss 0.12317 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  80 |    53/  269 batches | lr 0.000993 | 14.62 ms | loss 0.11778 | ppl     1.12\n",
            "| epoch  80 |   106/  269 batches | lr 0.000993 | 13.88 ms | loss 0.10138 | ppl     1.11\n",
            "| epoch  80 |   159/  269 batches | lr 0.000993 | 13.98 ms | loss 0.09658 | ppl     1.10\n",
            "| epoch  80 |   212/  269 batches | lr 0.000993 | 14.11 ms | loss 0.07427 | ppl     1.08\n",
            "| epoch  80 |   265/  269 batches | lr 0.000993 | 14.13 ms | loss 0.08787 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  80 | time: 10.76s | valid loss 0.09161 | valid ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  81 |    53/  269 batches | lr 0.000973 | 15.59 ms | loss 0.11799 | ppl     1.13\n",
            "| epoch  81 |   106/  269 batches | lr 0.000973 | 14.06 ms | loss 0.10248 | ppl     1.11\n",
            "| epoch  81 |   159/  269 batches | lr 0.000973 | 13.98 ms | loss 0.09673 | ppl     1.10\n",
            "| epoch  81 |   212/  269 batches | lr 0.000973 | 14.05 ms | loss 0.07442 | ppl     1.08\n",
            "| epoch  81 |   265/  269 batches | lr 0.000973 | 13.93 ms | loss 0.08805 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  81 | time:  4.45s | valid loss 0.12314 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  82 |    53/  269 batches | lr 0.000954 | 14.45 ms | loss 0.11958 | ppl     1.13\n",
            "| epoch  82 |   106/  269 batches | lr 0.000954 | 13.80 ms | loss 0.10339 | ppl     1.11\n",
            "| epoch  82 |   159/  269 batches | lr 0.000954 | 14.04 ms | loss 0.09677 | ppl     1.10\n",
            "| epoch  82 |   212/  269 batches | lr 0.000954 | 13.95 ms | loss 0.07338 | ppl     1.08\n",
            "| epoch  82 |   265/  269 batches | lr 0.000954 | 13.88 ms | loss 0.08757 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  82 | time:  4.37s | valid loss 0.12316 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  83 |    53/  269 batches | lr 0.000935 | 14.78 ms | loss 0.11799 | ppl     1.13\n",
            "| epoch  83 |   106/  269 batches | lr 0.000935 | 13.97 ms | loss 0.09981 | ppl     1.10\n",
            "| epoch  83 |   159/  269 batches | lr 0.000935 | 14.00 ms | loss 0.09620 | ppl     1.10\n",
            "| epoch  83 |   212/  269 batches | lr 0.000935 | 14.07 ms | loss 0.07364 | ppl     1.08\n",
            "| epoch  83 |   265/  269 batches | lr 0.000935 | 13.87 ms | loss 0.08777 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  83 | time:  4.40s | valid loss 0.12311 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  84 |    53/  269 batches | lr 0.000916 | 14.26 ms | loss 0.11787 | ppl     1.13\n",
            "| epoch  84 |   106/  269 batches | lr 0.000916 | 13.70 ms | loss 0.10357 | ppl     1.11\n",
            "| epoch  84 |   159/  269 batches | lr 0.000916 | 13.82 ms | loss 0.09663 | ppl     1.10\n",
            "| epoch  84 |   212/  269 batches | lr 0.000916 | 13.96 ms | loss 0.07351 | ppl     1.08\n",
            "| epoch  84 |   265/  269 batches | lr 0.000916 | 13.83 ms | loss 0.08757 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  84 | time:  4.34s | valid loss 0.12314 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  85 |    53/  269 batches | lr 0.000898 | 14.51 ms | loss 0.11764 | ppl     1.12\n",
            "| epoch  85 |   106/  269 batches | lr 0.000898 | 13.98 ms | loss 0.10030 | ppl     1.11\n",
            "| epoch  85 |   159/  269 batches | lr 0.000898 | 14.01 ms | loss 0.09631 | ppl     1.10\n",
            "| epoch  85 |   212/  269 batches | lr 0.000898 | 14.07 ms | loss 0.07369 | ppl     1.08\n",
            "| epoch  85 |   265/  269 batches | lr 0.000898 | 13.98 ms | loss 0.08776 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  85 | time:  4.40s | valid loss 0.12313 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  86 |    53/  269 batches | lr 0.000880 | 14.45 ms | loss 0.11766 | ppl     1.12\n",
            "| epoch  86 |   106/  269 batches | lr 0.000880 | 14.04 ms | loss 0.10006 | ppl     1.11\n",
            "| epoch  86 |   159/  269 batches | lr 0.000880 | 13.95 ms | loss 0.09614 | ppl     1.10\n",
            "| epoch  86 |   212/  269 batches | lr 0.000880 | 14.09 ms | loss 0.07362 | ppl     1.08\n",
            "| epoch  86 |   265/  269 batches | lr 0.000880 | 14.02 ms | loss 0.08779 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  86 | time:  4.39s | valid loss 0.12307 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  87 |    53/  269 batches | lr 0.000862 | 14.47 ms | loss 0.11855 | ppl     1.13\n",
            "| epoch  87 |   106/  269 batches | lr 0.000862 | 13.96 ms | loss 0.10207 | ppl     1.11\n",
            "| epoch  87 |   159/  269 batches | lr 0.000862 | 14.06 ms | loss 0.09617 | ppl     1.10\n",
            "| epoch  87 |   212/  269 batches | lr 0.000862 | 14.00 ms | loss 0.07332 | ppl     1.08\n",
            "| epoch  87 |   265/  269 batches | lr 0.000862 | 13.86 ms | loss 0.08762 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  87 | time:  4.38s | valid loss 0.12310 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  88 |    53/  269 batches | lr 0.000845 | 14.43 ms | loss 0.11828 | ppl     1.13\n",
            "| epoch  88 |   106/  269 batches | lr 0.000845 | 14.09 ms | loss 0.10087 | ppl     1.11\n",
            "| epoch  88 |   159/  269 batches | lr 0.000845 | 14.13 ms | loss 0.09625 | ppl     1.10\n",
            "| epoch  88 |   212/  269 batches | lr 0.000845 | 14.26 ms | loss 0.07332 | ppl     1.08\n",
            "| epoch  88 |   265/  269 batches | lr 0.000845 | 13.94 ms | loss 0.08748 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  88 | time:  4.40s | valid loss 0.12310 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  89 |    53/  269 batches | lr 0.000828 | 14.73 ms | loss 0.11676 | ppl     1.12\n",
            "| epoch  89 |   106/  269 batches | lr 0.000828 | 13.92 ms | loss 0.09937 | ppl     1.10\n",
            "| epoch  89 |   159/  269 batches | lr 0.000828 | 14.04 ms | loss 0.09581 | ppl     1.10\n",
            "| epoch  89 |   212/  269 batches | lr 0.000828 | 14.00 ms | loss 0.07297 | ppl     1.08\n",
            "| epoch  89 |   265/  269 batches | lr 0.000828 | 13.86 ms | loss 0.08751 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  89 | time:  4.39s | valid loss 0.12307 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  90 |    53/  269 batches | lr 0.000812 | 14.26 ms | loss 0.11743 | ppl     1.12\n",
            "| epoch  90 |   106/  269 batches | lr 0.000812 | 13.91 ms | loss 0.10102 | ppl     1.11\n",
            "| epoch  90 |   159/  269 batches | lr 0.000812 | 13.81 ms | loss 0.09599 | ppl     1.10\n",
            "| epoch  90 |   212/  269 batches | lr 0.000812 | 14.07 ms | loss 0.07336 | ppl     1.08\n",
            "| epoch  90 |   265/  269 batches | lr 0.000812 | 13.95 ms | loss 0.08759 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  90 | time: 10.65s | valid loss 0.09158 | valid ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:351: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  \"please use `get_last_lr()`.\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| epoch  91 |    53/  269 batches | lr 0.000795 | 15.35 ms | loss 0.11720 | ppl     1.12\n",
            "| epoch  91 |   106/  269 batches | lr 0.000795 | 14.05 ms | loss 0.10103 | ppl     1.11\n",
            "| epoch  91 |   159/  269 batches | lr 0.000795 | 13.95 ms | loss 0.09610 | ppl     1.10\n",
            "| epoch  91 |   212/  269 batches | lr 0.000795 | 14.19 ms | loss 0.07341 | ppl     1.08\n",
            "| epoch  91 |   265/  269 batches | lr 0.000795 | 13.92 ms | loss 0.08749 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  91 | time:  4.44s | valid loss 0.12308 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  92 |    53/  269 batches | lr 0.000779 | 14.89 ms | loss 0.11711 | ppl     1.12\n",
            "| epoch  92 |   106/  269 batches | lr 0.000779 | 13.92 ms | loss 0.09907 | ppl     1.10\n",
            "| epoch  92 |   159/  269 batches | lr 0.000779 | 13.71 ms | loss 0.09570 | ppl     1.10\n",
            "| epoch  92 |   212/  269 batches | lr 0.000779 | 13.94 ms | loss 0.07268 | ppl     1.08\n",
            "| epoch  92 |   265/  269 batches | lr 0.000779 | 14.00 ms | loss 0.08738 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  92 | time:  4.39s | valid loss 0.12307 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  93 |    53/  269 batches | lr 0.000764 | 14.55 ms | loss 0.11645 | ppl     1.12\n",
            "| epoch  93 |   106/  269 batches | lr 0.000764 | 14.07 ms | loss 0.09906 | ppl     1.10\n",
            "| epoch  93 |   159/  269 batches | lr 0.000764 | 14.21 ms | loss 0.09569 | ppl     1.10\n",
            "| epoch  93 |   212/  269 batches | lr 0.000764 | 13.79 ms | loss 0.07316 | ppl     1.08\n",
            "| epoch  93 |   265/  269 batches | lr 0.000764 | 13.84 ms | loss 0.08758 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  93 | time:  4.38s | valid loss 0.12304 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  94 |    53/  269 batches | lr 0.000749 | 14.22 ms | loss 0.11716 | ppl     1.12\n",
            "| epoch  94 |   106/  269 batches | lr 0.000749 | 13.77 ms | loss 0.10112 | ppl     1.11\n",
            "| epoch  94 |   159/  269 batches | lr 0.000749 | 13.80 ms | loss 0.09589 | ppl     1.10\n",
            "| epoch  94 |   212/  269 batches | lr 0.000749 | 13.75 ms | loss 0.07339 | ppl     1.08\n",
            "| epoch  94 |   265/  269 batches | lr 0.000749 | 13.82 ms | loss 0.08762 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  94 | time:  4.33s | valid loss 0.12308 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  95 |    53/  269 batches | lr 0.000734 | 14.20 ms | loss 0.11741 | ppl     1.12\n",
            "| epoch  95 |   106/  269 batches | lr 0.000734 | 13.96 ms | loss 0.09975 | ppl     1.10\n",
            "| epoch  95 |   159/  269 batches | lr 0.000734 | 13.91 ms | loss 0.09556 | ppl     1.10\n",
            "| epoch  95 |   212/  269 batches | lr 0.000734 | 13.82 ms | loss 0.07255 | ppl     1.08\n",
            "| epoch  95 |   265/  269 batches | lr 0.000734 | 13.86 ms | loss 0.08723 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  95 | time:  4.36s | valid loss 0.12305 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  96 |    53/  269 batches | lr 0.000719 | 14.42 ms | loss 0.11594 | ppl     1.12\n",
            "| epoch  96 |   106/  269 batches | lr 0.000719 | 13.84 ms | loss 0.09815 | ppl     1.10\n",
            "| epoch  96 |   159/  269 batches | lr 0.000719 | 13.87 ms | loss 0.09545 | ppl     1.10\n",
            "| epoch  96 |   212/  269 batches | lr 0.000719 | 13.93 ms | loss 0.07284 | ppl     1.08\n",
            "| epoch  96 |   265/  269 batches | lr 0.000719 | 13.91 ms | loss 0.08748 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  96 | time:  4.37s | valid loss 0.12304 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  97 |    53/  269 batches | lr 0.000705 | 14.32 ms | loss 0.11662 | ppl     1.12\n",
            "| epoch  97 |   106/  269 batches | lr 0.000705 | 13.92 ms | loss 0.10037 | ppl     1.11\n",
            "| epoch  97 |   159/  269 batches | lr 0.000705 | 14.13 ms | loss 0.09568 | ppl     1.10\n",
            "| epoch  97 |   212/  269 batches | lr 0.000705 | 13.93 ms | loss 0.07298 | ppl     1.08\n",
            "| epoch  97 |   265/  269 batches | lr 0.000705 | 13.94 ms | loss 0.08742 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  97 | time:  4.38s | valid loss 0.12305 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  98 |    53/  269 batches | lr 0.000690 | 14.67 ms | loss 0.11706 | ppl     1.12\n",
            "| epoch  98 |   106/  269 batches | lr 0.000690 | 14.02 ms | loss 0.09851 | ppl     1.10\n",
            "| epoch  98 |   159/  269 batches | lr 0.000690 | 13.95 ms | loss 0.09544 | ppl     1.10\n",
            "| epoch  98 |   212/  269 batches | lr 0.000690 | 13.99 ms | loss 0.07266 | ppl     1.08\n",
            "| epoch  98 |   265/  269 batches | lr 0.000690 | 13.84 ms | loss 0.08741 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  98 | time:  4.38s | valid loss 0.12304 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch  99 |    53/  269 batches | lr 0.000677 | 14.43 ms | loss 0.11621 | ppl     1.12\n",
            "| epoch  99 |   106/  269 batches | lr 0.000677 | 14.00 ms | loss 0.09858 | ppl     1.10\n",
            "| epoch  99 |   159/  269 batches | lr 0.000677 | 14.12 ms | loss 0.09547 | ppl     1.10\n",
            "| epoch  99 |   212/  269 batches | lr 0.000677 | 13.97 ms | loss 0.07297 | ppl     1.08\n",
            "| epoch  99 |   265/  269 batches | lr 0.000677 | 13.94 ms | loss 0.08750 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch  99 | time:  4.40s | valid loss 0.12303 | valid ppl     1.13\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch 100 |    53/  269 batches | lr 0.000663 | 14.49 ms | loss 0.11652 | ppl     1.12\n",
            "| epoch 100 |   106/  269 batches | lr 0.000663 | 13.88 ms | loss 0.09943 | ppl     1.10\n",
            "| epoch 100 |   159/  269 batches | lr 0.000663 | 13.97 ms | loss 0.09546 | ppl     1.10\n",
            "| epoch 100 |   212/  269 batches | lr 0.000663 | 13.99 ms | loss 0.07272 | ppl     1.08\n",
            "| epoch 100 |   265/  269 batches | lr 0.000663 | 13.89 ms | loss 0.08731 | ppl     1.09\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch 100 | time: 10.69s | valid loss 0.09154 | valid ppl     1.10\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hKvP0jEnQ08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}