{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WrFmbCFTCzuQ",
    "outputId": "de4fc3fc-683a-48cc-9033-23cf91f94e92"
   },
   "source": [
    "## 1. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WrFmbCFTCzuQ",
    "outputId": "de4fc3fc-683a-48cc-9033-23cf91f94e92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#stock(AAPL) prediction for the open price the next day with the past five days' prices utilized MAPE as the metric to evaluate the training results\n",
    "\n",
    "# coding: utf-8\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2onikeAC9Pu"
   },
   "source": [
    "## 2. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2onikeAC9Pu"
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2onikeAC9Pu"
   },
   "outputs": [],
   "source": [
    "def data_preprocessing(step_size):\n",
    "    '''\n",
    "    load data and transform data into trainset and testset\n",
    "    features: O,H,L,C \n",
    "    '''\n",
    "\n",
    "    df_final = pd.read_csv('./dataset/results_AAPL_new.csv')\n",
    "    df_final.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Pct_change_raw', 'Compound_multiplied_raw']\n",
    "\n",
    "    # avoid the data leakage problem\n",
    "    df_final['Pct_change'] = df_final['Pct_change_raw'].shift(1)\n",
    "    df_final.drop(['Pct_change_raw'], axis=1, inplace=True)\n",
    "    df_final['Compound_multiplied'] = df_final['Compound_multiplied_raw'].shift(1)\n",
    "    df_final.drop(['Compound_multiplied_raw'], axis=1, inplace=True)\n",
    "    df_final.dropna(axis=0, how='any', inplace=True)\n",
    "    dataset = df_final\n",
    "    dataset['Date'] = pd.to_datetime(dataset.Date, format='%Y-%m-%d')\n",
    "    dataset.index = dataset['Date']\n",
    "    dataset = dataset.sort_index(ascending=True, axis=0)\n",
    "    dataset.drop(['Date'], axis=1, inplace=True)\n",
    "\n",
    "    values = dataset.values #67*6\n",
    "\n",
    "    # ensure all data is float\n",
    "    values = values.astype('float32')\n",
    "\n",
    "    # normalize features\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled = scaler.fit_transform(values)\n",
    "\n",
    "    # frame as supervised learning\n",
    "    reframed = series_to_supervised(scaled, step_size, 1)  # 5\n",
    "    # print(reframed.shape) \n",
    "\n",
    "    # split into train and test sets\n",
    "    values = reframed.values\n",
    "\n",
    "    n_train_days = 61-1\n",
    "    train = values[:n_train_days, :]\n",
    "    test = values[n_train_days:, :]\n",
    "    \n",
    "    return train, test, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "kC0WLHlKDBeG",
    "outputId": "1c58f24b-7fe4-49b3-a7c1-07f2fe17b699"
   },
   "source": [
    "## 3. model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "kC0WLHlKDBeG",
    "outputId": "1c58f24b-7fe4-49b3-a7c1-07f2fe17b699"
   },
   "outputs": [],
   "source": [
    "step_size = 5\n",
    "feature_num = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "kC0WLHlKDBeG",
    "outputId": "1c58f24b-7fe4-49b3-a7c1-07f2fe17b699"
   },
   "source": [
    "## 4. Modeling\n",
    "### 4.1 Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "kC0WLHlKDBeG",
    "outputId": "1c58f24b-7fe4-49b3-a7c1-07f2fe17b699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 5, 6)              0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 5, 75)             24600     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 25)                10100     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 26        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 34,726\n",
      "Trainable params: 34,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_input = keras.Input(shape=(step_size,feature_num))\n",
    "x = layers.LSTM(75,return_sequences=True)(generator_input)\n",
    "#x = layers.Dropout(0.2)(x)\n",
    "x = layers.LSTM(25)(x)\n",
    "x = layers.Dense(1)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "kC0WLHlKDBeG",
    "outputId": "1c58f24b-7fe4-49b3-a7c1-07f2fe17b699"
   },
   "source": [
    "## 4.2 Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "kC0WLHlKDBeG",
    "outputId": "1c58f24b-7fe4-49b3-a7c1-07f2fe17b699"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 6, 1)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6, 72)             144       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 6, 72)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6, 100)            7300      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 6, 100)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6, 10)             1010      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 6, 10)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6, 1)              11        \n",
      "=================================================================\n",
      "Total params: 8,465\n",
      "Trainable params: 8,465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator_input = layers.Input(shape=(step_size+1,1))\n",
    "y = layers.Dense(72)(discriminator_input)\n",
    "y = layers.LeakyReLU(alpha=0.05)(y)\n",
    "y = layers.Dense(100)(y)\n",
    "y = layers.LeakyReLU(alpha=0.05)(y)\n",
    "y = layers.Dense(10)(y)\n",
    "y = layers.LeakyReLU(alpha=0.05)(y)\n",
    "y = layers.Dense(1,activation='sigmoid')(y)\n",
    "\n",
    "discriminator = keras.models.Model(discriminator_input, y)\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "m8G26dD5DGKN",
    "outputId": "30031bfd-66f6-49a3-cae6-d6d88e59935a"
   },
   "source": [
    "## 5. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "m8G26dD5DGKN",
    "outputId": "30031bfd-66f6-49a3-cae6-d6d88e59935a"
   },
   "outputs": [],
   "source": [
    "discriminator_optimizer = keras.optimizers.RMSprop(lr=8e-4, clipvalue=1.0, decay=1e-8)\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')\n",
    "\n",
    "# Optimizer정의 \n",
    "discriminator.trainable = False\n",
    "gan_input = keras.Input(shape=(step_size, feature_num))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "gan_optimizer = keras.optimizers.RMSprop(lr=4e-4, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "m8G26dD5DGKN",
    "outputId": "30031bfd-66f6-49a3-cae6-d6d88e59935a"
   },
   "source": [
    "## 6. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "m8G26dD5DGKN",
    "outputId": "30031bfd-66f6-49a3-cae6-d6d88e59935a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 30) 60 (60,)\n"
     ]
    }
   ],
   "source": [
    "# PREPARATION OF TIME SERIES DATASET\n",
    "train,test,scaler = data_preprocessing(step_size)\n",
    "\n",
    "# split into input and outputs\n",
    "n_obs = step_size * feature_num\n",
    "train_X, train_Y = train[:, :n_obs], train[:, -feature_num] #choose the first feature,namely 'open price'\n",
    "test_X, test_Y = test[:, :n_obs], test[:, -feature_num]  # !!!!!!!!!!!!!!!\n",
    "\n",
    "print(train_X.shape, len(train_X), train_Y.shape) #train_X 280*30,train_Y  280*6\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "trainX = train_X.reshape((train_X.shape[0], step_size, feature_num))\n",
    "testX = test_X.reshape((test_X.shape[0], step_size, feature_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "m8G26dD5DGKN",
    "outputId": "30031bfd-66f6-49a3-cae6-d6d88e59935a"
   },
   "source": [
    "## 7. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "m8G26dD5DGKN",
    "outputId": "30031bfd-66f6-49a3-cae6-d6d88e59935a"
   },
   "outputs": [],
   "source": [
    "#파라메터정의 \n",
    "iterations = 61-1\n",
    "batch_size = 1\n",
    "start = 0\n",
    "final = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nNbB82qODsqX",
    "outputId": "bd830b18-f6d6-4174-e7c4-a926440e13bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yckim\\Anaconda3\\envs\\TS_sample2\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "C:\\Users\\yckim\\Anaconda3\\envs\\TS_sample2\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n",
      "C:\\Users\\yckim\\Anaconda3\\envs\\TS_sample2\\lib\\site-packages\\keras\\engine\\training.py:297: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training result: 0.018379634\n"
     ]
    }
   ],
   "source": [
    "#이터레이션 시작 \n",
    "for step in range(iterations):\n",
    "    #print(step)\n",
    "    temp_X = copy.deepcopy(trainX[step])\n",
    "    temp_X = temp_X.reshape(batch_size,step_size,feature_num)\n",
    "    temp_Y = copy.deepcopy(train_Y[step])\n",
    "    temp_Y = temp_Y.reshape(batch_size,1)\n",
    "    predictions = generator.predict(temp_X)\n",
    "\n",
    "    # discrriminator \n",
    "    for i in range(25):\n",
    "        aaa = trainX[step]\n",
    "        input_f = np.concatenate([np.transpose(np.array([aaa[:,0]])), predictions], 0)\n",
    "        input_r = np.concatenate([np.transpose(np.array([aaa[:,0]])), temp_Y], 0)\n",
    "        input = np.concatenate([[input_f],[input_r]])\n",
    "        labels = np.concatenate([[np.ones((6, 1))], [np.zeros((6, 1))]])\n",
    "        d_loss = discriminator.train_on_batch(input, labels)\n",
    "\n",
    "    # generator \n",
    "    for i in range(5):\n",
    "        misleading_targets = np.zeros((batch_size, 1))\n",
    "        a_loss = gan.train_on_batch(temp_X, [misleading_targets])\n",
    "    \n",
    "    final.append(predictions[0])\n",
    "    \n",
    "final = np.concatenate((np.array(final), train_X[:, -5:]), axis=1)    \n",
    "final2 = np.concatenate((np.transpose(np.array([train_Y])), train_X[:, -5:]), axis=1)\n",
    "int1 = scaler.inverse_transform(final)\n",
    "int2 = scaler.inverse_transform(final2)\n",
    "MAPE_O1 = np.mean(np.abs((int2[:,0] - int1[:,0]) / int2[:,0]))\n",
    "print('training result:',MAPE_O1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rkPoil7tDqZ-",
    "outputId": "d6d6cecc-0aad-4aad-c34a-8ca7b969c101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing result: 0.0057290397\n"
     ]
    }
   ],
   "source": [
    "final = []\n",
    "for step in range(5):\n",
    "    temp_X = copy.deepcopy(testX[step])\n",
    "    temp_X = temp_X.reshape(batch_size, step_size, feature_num)\n",
    "    predictions = generator.predict(temp_X)\n",
    "    final.append(predictions[0])\n",
    "\n",
    "final = np.concatenate((np.array(final), test_X[:, -5:]), axis=1)\n",
    "final2 = np.concatenate((np.transpose(np.array([test_Y])), test_X[:, -5:]), axis=1)\n",
    "int1 = scaler.inverse_transform(final)\n",
    "int2 = scaler.inverse_transform(final2)\n",
    "MAPE_O2 = np.mean(np.abs((int2[:,0] - int1[:,0]) / int2[:,0]))\n",
    "print('testing result:',MAPE_O2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (TS_sample2)",
   "language": "python",
   "name": "ts_sample2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
