# -*- coding: utf-8 -*-
"""2. OCI_scm_unitprice_forecast_prophet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QuLHDn9cx8tiBbD2NkIeu7-_i6tuhPRV
"""

from google.colab import drive
drive.mount('/gdrive', force_remount=True)

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import warnings
import itertools
import numpy as np
import random
import statsmodels.api as sm
# prophet by Facebook
from fbprophet import Prophet
# time series analysis
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.metrics import mean_squared_error, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns
warnings.filterwarnings("ignore")
plt.style.use('fivethirtyeight')

folderName  = "/gdrive/My Drive/colab/Sale_data/dataset"
fileName = "scm_total.csv"
dataSource = folderName + "/" + fileName
print(dataSource)

def reduce_mem_usage(df, verbose=True):
    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']
    start_mem = df.memory_usage().sum() / 1024**2    
    for col in df.columns:
        col_type = df[col].dtypes
        if col_type in numerics:
            c_min = df[col].min()
            c_max = df[col].max()
            if str(col_type)[:3] == 'int':
                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:
                    df[col] = df[col].astype(np.int8)
                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:
                    df[col] = df[col].astype(np.int16)
                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:
                    df[col] = df[col].astype(np.int32)
                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:
                    df[col] = df[col].astype(np.int64)  
            else:
                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:
                    df[col] = df[col].astype(np.float16)
                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:
                    df[col] = df[col].astype(np.float32)
                else:
                    df[col] = df[col].astype(np.float64)    
    end_mem = df.memory_usage().sum() / 1024**2
    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))
    return df

df = pd.read_csv(dataSource)
df = reduce_mem_usage(df)

print('-'*60)
print('*** Head of the dataframe ***')
print('-'*60)
print(df.head())
print('-'*60)
print('*** Tail of the dataframe ***')
print('-'*60)
print(df.tail())

df.info()

df.head()

df["timestamp"] = pd.to_datetime(df["ap_date"])
df["Date"] = pd.to_datetime(df["ap_date"])
df.set_index("timestamp", inplace=True)
df.head()

fig, ax = plt.subplots(figsize=(20, 7))
a = sns.lineplot(x="Date", y="days_unit_price", data=df)
a.set_title("Daily unit prices", fontsize=15)
plt.show()

"""## 1. Month 기준"""

df_month = df.resample("M").sum()

fig, ax = plt.subplots(2, 1, figsize=(10, 3))
fig.set_size_inches(8,12)

df_month["days_unit_price"].plot.line(ax=ax[0])
np.log(df_month["days_unit_price"]).plot.line(ax=ax[1])
ax[0].set_title("month_unit_price")
ax[1].set_title("log month_unit_price")
plt.show()

sns.distplot(df_month["days_ap_kor_amt"])
print("skew of month_days_unit_price: ", df_month["days_unit_price"].skew())
print("kurtosis of month_days_unit_price : ", df_month["days_unit_price"].kurtosis())

sns.distplot(np.log(df_month["days_unit_price"]))
print("skew of log(days_unit_price):", np.log(df_month["days_unit_price"]).skew())
print("kurtosis of log(days_unit_price) : ", np.log(df_month["days_unit_price"]).kurtosis())

"""## 2. Quarter 기준"""

df_quarter = df.resample("Q").sum()

fig, ax = plt.subplots(2, 1, figsize=(10, 3))
fig.set_size_inches(8,12)

df_quarter["days_unit_price"].plot.line(ax=ax[0])
np.log(df_quarter["days_unit_price"]).plot.line(ax=ax[1])
ax[0].set_title("quarter_unit_price")
ax[1].set_title("log quarter_unit_price")
plt.show()

sns.distplot(df_quarter["days_unit_price"])
print("skew of month_days_unit_price: ", df_quarter["days_unit_price"].skew())
print("kurtosis of month_days_unit_price : ", df_quarter["days_unit_price"].kurtosis())

sns.distplot(np.log(df_quarter["days_unit_price"]))
print("skew of log(days_unit_price):", np.log(df_quarter["days_unit_price"]).skew())
print("kurtosis of log(days_unit_price) : ", np.log(df_quarter["days_unit_price"]).kurtosis())

"""## 1. 공장별 거래 transactions"""

fig, ax = plt.subplots(figsize=(20, 20))
x = df["org_display"].value_counts().index.values
y = df["org_display"].value_counts().values

sns.barplot(ax=ax, x=x, y=y)
plt.xlabel("transaction counts")
plt.ylabel("OCI 공장")
plt.show()
# Iksan VIP의 경우 거래량이 상대적으로 적은 것을 알 수 있음

"""## 2. 공장별 unit_price의 총 합"""

fig, ax = plt.subplots(figsize=(20, 7))
monthAggregated = pd.DataFrame(df.groupby("org_display")["days_unit_price"].sum()).reset_index().sort_values('days_unit_price')
sns.barplot(data=monthAggregated,x="org_display",y="days_unit_price",ax=ax)
ax.set(xlabel='org_display', ylabel='Total unit_price received')
ax.set_title("Total unit_price received org_display",fontsize=15)
plt.show()

"""## 3. 시간별 분석을 위한 utils"""

def date_features(df, label=None):
    df = df.copy()

    df['date'] = df.Date
    df['month'] = df['date'].dt.strftime('%B')
    df['year'] = df['date'].dt.strftime('%Y')
    df['dayofweek'] = df['date'].dt.strftime('%A')
    df['quarter'] = df['date'].dt.quarter
    df['dayofyear'] = df['date'].dt.dayofyear
    df['dayofmonth'] = df['date'].dt.day
    df['weekofyear'] = df['date'].dt.weekofyear
    
    X = df[['dayofweek','quarter','month','year',
           'dayofyear','dayofmonth','weekofyear']]
    if label:
        y = df[label]
        return X, y
    return X
    
X, y = date_features(df, label='days_unit_price')
df_new = pd.concat([X, y], axis=1)
df_new.head()

"""## 5. 년도별 월별 unit_price"""

fig, ax = plt.subplots(figsize=(30, 15))
palette = sns.color_palette("mako_r", 4)
a = sns.barplot(x="month", y="days_unit_price", hue="year", data=df_new, ci=None)
a.set_title("days_unit_price Data", fontsize=15)
plt.legend(loc="upper right")
plt.show()

fig,(ax1,ax2,ax3,ax4)= plt.subplots(nrows=4)
fig.set_size_inches(20,30)

monthAggregated = pd.DataFrame(df_new.groupby("month")["days_unit_price"].sum()).reset_index().sort_values('days_unit_price')
sns.barplot(data=monthAggregated,x="month",y="days_unit_price",ax=ax1)
ax1.set(xlabel='Month', ylabel='Total unit_price received')
ax1.set_title("Total unit_price received By Month",fontsize=15)

monthAggregated = pd.DataFrame(df_new.groupby("dayofweek")["days_unit_price"].sum()).reset_index().sort_values('days_unit_price')
sns.barplot(data=monthAggregated,x="dayofweek",y="days_unit_price",ax=ax2)
ax2.set(xlabel='dayofweek', ylabel='Total unit_price received')
ax2.set_title("Total unit_price received By Weekday",fontsize=15)

monthAggregated = pd.DataFrame(df_new.groupby("quarter")["days_unit_price"].sum()).reset_index().sort_values('days_unit_price')
sns.barplot(data=monthAggregated,x="quarter",y="days_unit_price",ax=ax3)
ax3.set(xlabel='Quarter', ylabel='Total unit_price received')
ax3.set_title("Total unit_price received By Quarter",fontsize=15)

monthAggregated = pd.DataFrame(df_new.groupby("year")["days_unit_price"].sum()).reset_index().sort_values('days_unit_price')
sns.barplot(data=monthAggregated,x="year",y="days_unit_price",ax=ax4)
ax4.set(xlabel='year', ylabel='Total unit_price received')
ax4.set_title("Total unit_price received By year",fontsize=15)

"""## Month 기준 Forecast"""

df = df.resample("M").sum()
df = df.drop(["days_ap_kor_amt", "days_unit_ap_qty", "incremental_number"], axis=1)
df.reset_index(inplace=True)
df.head()

df=df.rename(columns={'timestamp':'ds','days_unit_price':'y'})

print(f"y_max : {df['y'].max()}, y_min : {df['y'].min()}")

sns.distplot(df["y"])

primal_date = '2019-8-31'
end_date = '2020-03-01'
mask1 = (df['ds'] <= primal_date)
mask2 = (df['ds'] > primal_date)
mask3 = (df['ds'] < end_date)

X_tr = df.loc[mask1]
X_tst = df.loc[mask2]
X_tst = X_tst.loc[mask3]
print("train shape",X_tr.shape)
print("test shape",X_tst.shape)

X_tst.tail(10)

X_tr.describe()

X_tst.describe()

pd.plotting.register_matplotlib_converters()
f, ax = plt.subplots(figsize=(14,5))
X_tr.plot(kind='line', x='ds', y='y', color='blue', label='Train', ax=ax)
X_tst.plot(kind='line', x='ds', y='y', color='red', label='Test', ax=ax)
plt.title('Sales Amount Traning and Test data')
plt.show()

def mean_absolute_percentage_error(y_true, y_pred): 
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

"""## Simple Prophet Model"""

X_tr.head()

X_tst.tail(20)

model = Prophet()
model.fit(X_tr)

future = model.make_future_dataframe(periods=6, freq="M")
forecast = model.predict(future)
forecast[["ds", "yhat", "yhat_lower", "yhat_upper"]].tail(7)

fig = model.plot_components(forecast)

# Plot the forecast
f, ax = plt.subplots(1)
f.set_figheight(5)
f.set_figwidth(15)
fig = model.plot(forecast,ax=ax)
plt.show()

"""## Actual vs Prediction Comparison"""

X_tst_forecast = model.predict(X_tst)
X_tst_forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(7)

# Plot the forecast with the actuals
f, ax = plt.subplots(1)
f.set_figheight(5)
f.set_figwidth(15)
ax.scatter(X_tst.ds, X_tst['y'], color='r')
fig = model.plot(X_tst_forecast, ax=ax)

"""## 3.2 Compare the test Sales and forecasted Sales"""

f, ax = plt.subplots(figsize=(14,5))
f.set_figheight(5)
f.set_figwidth(15)
X_tst.plot(kind='line',x='ds', y='y', color='red', label='Test', ax=ax)
X_tst_forecast.plot(kind='line',x='ds',y='yhat', color='green',label='Forecast', ax=ax)
plt.title('February 2020 Forecast vs Actuals')
plt.show()

import datetime

# Plot the forecast with the actuals
f, ax = plt.subplots(1)
f.set_figheight(5)
f.set_figwidth(15)
ax.scatter(X_tst.ds, X_tst['y'], color='r')
fig = model.plot(X_tst_forecast, ax=ax)
# ax.set_xlim([datetime.date(2019, 9, 15), datetime.date(2020, 3, 1)])
# ax.set_ylim(-300000000000, 300000000000)
# ax.set_ylim(-1, 4)
plot = plt.suptitle('2019-08-31 ~ 2020-03-01 Forecast vs Actuals')

mape = mean_absolute_percentage_error(X_tst['y'],X_tst_forecast['yhat'])
print("MAPE",round(mape,4))

"""# 4. HyperParameter Tuning using ParameterGrid"""

from sklearn.model_selection import ParameterGrid
params_grid = {'seasonality_mode':('multiplicative','additive'),
               'changepoint_prior_scale':[0.1,0.2,0.3,0.4,0.5],
               'n_changepoints' : [100,150,200]}
grid = ParameterGrid(params_grid)

cnt = 0
for p in grid:
    cnt = cnt+1

print('Total Possible Models',cnt)

strt = '2019-8-31'
end = '2020-03-01'

model_parameters = pd.DataFrame(columns = ["MAPE", "Parameters"])
for p in grid:
    test = pd.DataFrame()
    print(p)
    random.seed(0)
    train_model = Prophet(changepoint_prior_scale = p['changepoint_prior_scale'],
                         n_changepoints = p['n_changepoints'],
                         seasonality_mode = p['seasonality_mode'],
                         weekly_seasonality=True,
                         daily_seasonality = True,
                         yearly_seasonality = True, 
                         interval_width=0.95)
    
    train_model.fit(X_tr)
    train_forecast = train_model.make_future_dataframe(periods=6, freq='M',include_history = False)
    train_forecast = train_model.predict(train_forecast)
    test=train_forecast[['ds','yhat']]
    Actual = df[(df['ds']>strt) & (df['ds']<=end)]
    MAPE = mean_absolute_percentage_error(Actual['y'],abs(test['yhat']))
    print('Mean Absolute Percentage Error(MAPE)------------------------------------',MAPE)
    model_parameters = model_parameters.append({'MAPE':MAPE,'Parameters':p},ignore_index=True)

parameters = model_parameters.sort_values(by=['MAPE'])
parameters = parameters.reset_index(drop=True)
parameters.head()

parameters['Parameters'][0]

# Setup and train model with holidays
final_model = Prophet(changepoint_prior_scale= 0.1,
                      n_changepoints = 100,
                      seasonality_mode = 'multiplicative')
final_model.fit(X_tr)

future = final_model.make_future_dataframe(periods=6, freq='M')
forecast = final_model.predict(future)
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(7)

# Plot the components of the model
fig = final_model.plot_components(forecast)

# Plot the forecast
f, ax = plt.subplots(1)
f.set_figheight(5)
f.set_figwidth(15)
fig = final_model.plot(forecast,ax=ax)
plt.show()

"""### Final model : Test"""

X_tst_final= final_model.predict(X_tst)
X_tst_final[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(7)

f, ax = plt.subplots(figsize=(14,5))
f.set_figheight(5)
f.set_figwidth(15)
X_tst.plot(kind='line',x='ds', y='y', color='red', label='Actual', ax=ax)
X_tst_final.plot(kind='line',x='ds',y='yhat', color='green',label='Forecast', ax=ax)
plt.title('Jan & Feb 2020 Forecast vs Actuals')
plt.show()

MAPE = mean_absolute_percentage_error(X_tst['y'],abs(X_tst_final['yhat']))
print('MAPE', MAPE)

df.to_csv("/gdrive/My Drive/colab/Sale_data/dataset/final/preprocessed_data.csv")

forecast.to_csv("/gdrive/My Drive/colab/Sale_data/dataset/final/forecast_train.csv")

X_tst_final.to_csv("/gdrive/My Drive/colab/Sale_data/dataset/final/forecast_test_result.csv")

